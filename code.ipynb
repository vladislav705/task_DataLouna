{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80c237f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "import pandasql as pql\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349c018b",
   "metadata": {},
   "source": [
    "## Подгрузим датасеты, сделаем предобработку:\n",
    "Нам не важно первый игрок или второй играют хорошо, поэтому сделаем аггрегацию по игрокам. Возьмем их средние характеристики, при этом, чтобы не потерять всю информацию, возьмем так же стандартное отклонение среди игроков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4fd5109",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bbf16bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>map_id</th>\n",
       "      <th>team1_id</th>\n",
       "      <th>team2_id</th>\n",
       "      <th>map_name</th>\n",
       "      <th>who_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>289</td>\n",
       "      <td>6665</td>\n",
       "      <td>7718</td>\n",
       "      <td>Ancient</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>715</td>\n",
       "      <td>4411</td>\n",
       "      <td>10577</td>\n",
       "      <td>Inferno</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157</td>\n",
       "      <td>11251</td>\n",
       "      <td>9455</td>\n",
       "      <td>Nuke</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>524</td>\n",
       "      <td>4608</td>\n",
       "      <td>7532</td>\n",
       "      <td>Mirage</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>404</td>\n",
       "      <td>8637</td>\n",
       "      <td>6667</td>\n",
       "      <td>Overpass</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>709</td>\n",
       "      <td>6667</td>\n",
       "      <td>4773</td>\n",
       "      <td>Inferno</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>528</td>\n",
       "      <td>9215</td>\n",
       "      <td>5995</td>\n",
       "      <td>Ancient</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>163</td>\n",
       "      <td>4869</td>\n",
       "      <td>9565</td>\n",
       "      <td>Mirage</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>96</td>\n",
       "      <td>10426</td>\n",
       "      <td>4991</td>\n",
       "      <td>Nuke</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>243</td>\n",
       "      <td>7532</td>\n",
       "      <td>9565</td>\n",
       "      <td>Mirage</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>713 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     map_id  team1_id  team2_id  map_name  who_win\n",
       "0       289      6665      7718   Ancient        0\n",
       "1       715      4411     10577   Inferno        0\n",
       "2       157     11251      9455      Nuke        1\n",
       "3       524      4608      7532    Mirage        0\n",
       "4       404      8637      6667  Overpass        1\n",
       "..      ...       ...       ...       ...      ...\n",
       "708     709      6667      4773   Inferno        0\n",
       "709     528      9215      5995   Ancient        1\n",
       "710     163      4869      9565    Mirage        1\n",
       "711      96     10426      4991      Nuke        1\n",
       "712     243      7532      9565    Mirage        1\n",
       "\n",
       "[713 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59250527",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3add299e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dae21b",
   "metadata": {},
   "source": [
    "### Проверим, что в тесте играют те же команды, иначе возникнут трудности при one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14fb6497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(list(df_train.team1_id.values)+list(df_train.team2_id.values)+list(df_test.team1_id.values)+list(df_test.team2_id.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f491da7",
   "metadata": {},
   "source": [
    "#### Все ок, новых команд нет\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a9f59f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_train, df_test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56fad651",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f723fdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c180023",
   "metadata": {},
   "outputs": [],
   "source": [
    "players_feats = pd.read_csv('players_feats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "596b47de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1_id</th>\n",
       "      <th>p1_total_kills</th>\n",
       "      <th>p1_headshots</th>\n",
       "      <th>p1_total_deaths</th>\n",
       "      <th>p1_kd_ratio</th>\n",
       "      <th>p1_damage_per_round</th>\n",
       "      <th>p1_grenade_damage_per_round</th>\n",
       "      <th>p1_maps_played</th>\n",
       "      <th>p1_rounds_played</th>\n",
       "      <th>p1_kills_per_round</th>\n",
       "      <th>...</th>\n",
       "      <th>p5_kill_death_difference</th>\n",
       "      <th>p5_total_opening_kills</th>\n",
       "      <th>p5_total_opening_deaths</th>\n",
       "      <th>p5_opening_kill_ratio</th>\n",
       "      <th>p5_opening_kill_rating</th>\n",
       "      <th>p5_team_win_percent_after_first_kill</th>\n",
       "      <th>p5_first_kill_in_won_rounds</th>\n",
       "      <th>team_id</th>\n",
       "      <th>map_name</th>\n",
       "      <th>map_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4954</td>\n",
       "      <td>90</td>\n",
       "      <td>42.2</td>\n",
       "      <td>112</td>\n",
       "      <td>0.80</td>\n",
       "      <td>76.3</td>\n",
       "      <td>5.9</td>\n",
       "      <td>6</td>\n",
       "      <td>156</td>\n",
       "      <td>0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.28</td>\n",
       "      <td>84.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6665</td>\n",
       "      <td>Ancient</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5794</td>\n",
       "      <td>45</td>\n",
       "      <td>60.0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.79</td>\n",
       "      <td>82.3</td>\n",
       "      <td>10.9</td>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>0.66</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>54</td>\n",
       "      <td>34</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.17</td>\n",
       "      <td>70.4</td>\n",
       "      <td>16.7</td>\n",
       "      <td>7532</td>\n",
       "      <td>Ancient</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4954</td>\n",
       "      <td>156</td>\n",
       "      <td>51.9</td>\n",
       "      <td>167</td>\n",
       "      <td>0.93</td>\n",
       "      <td>63.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>10</td>\n",
       "      <td>265</td>\n",
       "      <td>0.59</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.10</td>\n",
       "      <td>88.5</td>\n",
       "      <td>20.5</td>\n",
       "      <td>6665</td>\n",
       "      <td>Dust2</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5794</td>\n",
       "      <td>449</td>\n",
       "      <td>53.5</td>\n",
       "      <td>427</td>\n",
       "      <td>1.05</td>\n",
       "      <td>86.7</td>\n",
       "      <td>13.1</td>\n",
       "      <td>23</td>\n",
       "      <td>618</td>\n",
       "      <td>0.73</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>62</td>\n",
       "      <td>49</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.10</td>\n",
       "      <td>79.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>7532</td>\n",
       "      <td>Dust2</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7998</td>\n",
       "      <td>173</td>\n",
       "      <td>32.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1.33</td>\n",
       "      <td>82.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>9</td>\n",
       "      <td>225</td>\n",
       "      <td>0.77</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.08</td>\n",
       "      <td>81.5</td>\n",
       "      <td>16.2</td>\n",
       "      <td>4608</td>\n",
       "      <td>Dust2</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>9031</td>\n",
       "      <td>69</td>\n",
       "      <td>49.3</td>\n",
       "      <td>70</td>\n",
       "      <td>0.99</td>\n",
       "      <td>69.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4</td>\n",
       "      <td>114</td>\n",
       "      <td>0.61</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.11</td>\n",
       "      <td>75.0</td>\n",
       "      <td>21.4</td>\n",
       "      <td>10503</td>\n",
       "      <td>Ancient</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>7716</td>\n",
       "      <td>104</td>\n",
       "      <td>55.8</td>\n",
       "      <td>113</td>\n",
       "      <td>0.92</td>\n",
       "      <td>71.6</td>\n",
       "      <td>5.9</td>\n",
       "      <td>6</td>\n",
       "      <td>172</td>\n",
       "      <td>0.60</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.30</td>\n",
       "      <td>75.8</td>\n",
       "      <td>28.4</td>\n",
       "      <td>7020</td>\n",
       "      <td>Vertigo</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>12521</td>\n",
       "      <td>141</td>\n",
       "      <td>37.6</td>\n",
       "      <td>159</td>\n",
       "      <td>0.89</td>\n",
       "      <td>79.7</td>\n",
       "      <td>7.4</td>\n",
       "      <td>8</td>\n",
       "      <td>210</td>\n",
       "      <td>0.67</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.77</td>\n",
       "      <td>55.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>8297</td>\n",
       "      <td>Vertigo</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>7716</td>\n",
       "      <td>155</td>\n",
       "      <td>58.7</td>\n",
       "      <td>154</td>\n",
       "      <td>1.01</td>\n",
       "      <td>71.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>10</td>\n",
       "      <td>246</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.39</td>\n",
       "      <td>83.3</td>\n",
       "      <td>22.9</td>\n",
       "      <td>7020</td>\n",
       "      <td>Ancient</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>12521</td>\n",
       "      <td>108</td>\n",
       "      <td>32.4</td>\n",
       "      <td>134</td>\n",
       "      <td>0.81</td>\n",
       "      <td>76.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7</td>\n",
       "      <td>185</td>\n",
       "      <td>0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.03</td>\n",
       "      <td>89.5</td>\n",
       "      <td>15.6</td>\n",
       "      <td>8297</td>\n",
       "      <td>Ancient</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1486 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      p1_id  p1_total_kills  p1_headshots  p1_total_deaths  p1_kd_ratio  \\\n",
       "0      4954              90          42.2              112         0.80   \n",
       "1      5794              45          60.0               57         0.79   \n",
       "2      4954             156          51.9              167         0.93   \n",
       "3      5794             449          53.5              427         1.05   \n",
       "4      7998             173          32.9              130         1.33   \n",
       "...     ...             ...           ...              ...          ...   \n",
       "1481   9031              69          49.3               70         0.99   \n",
       "1482   7716             104          55.8              113         0.92   \n",
       "1483  12521             141          37.6              159         0.89   \n",
       "1484   7716             155          58.7              154         1.01   \n",
       "1485  12521             108          32.4              134         0.81   \n",
       "\n",
       "      p1_damage_per_round  p1_grenade_damage_per_round  p1_maps_played  \\\n",
       "0                    76.3                          5.9               6   \n",
       "1                    82.3                         10.9               3   \n",
       "2                    63.5                          3.4              10   \n",
       "3                    86.7                         13.1              23   \n",
       "4                    82.4                          2.9               9   \n",
       "...                   ...                          ...             ...   \n",
       "1481                 69.8                          5.7               4   \n",
       "1482                 71.6                          5.9               6   \n",
       "1483                 79.7                          7.4               8   \n",
       "1484                 71.1                          7.9              10   \n",
       "1485                 76.3                          5.2               7   \n",
       "\n",
       "      p1_rounds_played  p1_kills_per_round  ...  p5_kill_death_difference  \\\n",
       "0                  156                0.58  ...                         5   \n",
       "1                   68                0.66  ...                        96   \n",
       "2                  265                0.59  ...                        22   \n",
       "3                  618                0.73  ...                       104   \n",
       "4                  225                0.77  ...                        19   \n",
       "...                ...                 ...  ...                       ...   \n",
       "1481               114                0.61  ...                        -1   \n",
       "1482               172                0.60  ...                         4   \n",
       "1483               210                0.67  ...                         5   \n",
       "1484               246                0.63  ...                        35   \n",
       "1485               185                0.58  ...                         9   \n",
       "\n",
       "      p5_total_opening_kills  p5_total_opening_deaths  p5_opening_kill_ratio  \\\n",
       "0                         25                       12                   2.08   \n",
       "1                         54                       34                   1.59   \n",
       "2                         26                       19                   1.37   \n",
       "3                         62                       49                   1.27   \n",
       "4                         27                       25                   1.08   \n",
       "...                      ...                      ...                    ...   \n",
       "1481                      16                       18                   0.89   \n",
       "1482                      33                       34                   0.97   \n",
       "1483                       9                       15                   0.60   \n",
       "1484                      30                       17                   1.76   \n",
       "1485                      19                       17                   1.12   \n",
       "\n",
       "      p5_opening_kill_rating  p5_team_win_percent_after_first_kill  \\\n",
       "0                       1.28                                  84.0   \n",
       "1                       1.17                                  70.4   \n",
       "2                       1.10                                  88.5   \n",
       "3                       1.10                                  79.0   \n",
       "4                       1.08                                  81.5   \n",
       "...                      ...                                   ...   \n",
       "1481                    1.11                                  75.0   \n",
       "1482                    1.30                                  75.8   \n",
       "1483                    0.77                                  55.6   \n",
       "1484                    1.39                                  83.3   \n",
       "1485                    1.03                                  89.5   \n",
       "\n",
       "      p5_first_kill_in_won_rounds  team_id  map_name  map_id  \n",
       "0                            25.0     6665   Ancient     635  \n",
       "1                            16.7     7532   Ancient     635  \n",
       "2                            20.5     6665     Dust2     583  \n",
       "3                            17.4     7532     Dust2     583  \n",
       "4                            16.2     4608     Dust2     439  \n",
       "...                           ...      ...       ...     ...  \n",
       "1481                         21.4    10503   Ancient     284  \n",
       "1482                         28.4     7020   Vertigo      27  \n",
       "1483                          4.3     8297   Vertigo      27  \n",
       "1484                         22.9     7020   Ancient     237  \n",
       "1485                         15.6     8297   Ancient     237  \n",
       "\n",
       "[1486 rows x 128 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d870e86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "players_feats = players_feats.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fb4a06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1470"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(players_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97dc91be",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''select * from \n",
    "players_feats, df_train\n",
    "where (df_train.map_id = players_feats.map_id and df_train.team1_id = players_feats.team_id)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f10d3d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "totall_df = pql.sqldf(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5aae3c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p1_id',\n",
       " 'p1_total_kills',\n",
       " 'p1_headshots',\n",
       " 'p1_total_deaths',\n",
       " 'p1_kd_ratio',\n",
       " 'p1_damage_per_round',\n",
       " 'p1_grenade_damage_per_round',\n",
       " 'p1_maps_played',\n",
       " 'p1_rounds_played',\n",
       " 'p1_kills_per_round',\n",
       " 'p1_assists_per_round',\n",
       " 'p1_deaths_per_round',\n",
       " 'p1_saved_by_teammate_per_round',\n",
       " 'p1_saved_teammates_per_round',\n",
       " 'p1_rating',\n",
       " 'p1_kill_death',\n",
       " 'p1_kill_round',\n",
       " 'p1_rounds_with_kills',\n",
       " 'p1_kill_death_difference',\n",
       " 'p1_total_opening_kills',\n",
       " 'p1_total_opening_deaths',\n",
       " 'p1_opening_kill_ratio',\n",
       " 'p1_opening_kill_rating',\n",
       " 'p1_team_win_percent_after_first_kill',\n",
       " 'p1_first_kill_in_won_rounds',\n",
       " 'p2_id',\n",
       " 'p2_total_kills',\n",
       " 'p2_headshots',\n",
       " 'p2_total_deaths',\n",
       " 'p2_kd_ratio',\n",
       " 'p2_damage_per_round',\n",
       " 'p2_grenade_damage_per_round',\n",
       " 'p2_maps_played',\n",
       " 'p2_rounds_played',\n",
       " 'p2_kills_per_round',\n",
       " 'p2_assists_per_round',\n",
       " 'p2_deaths_per_round',\n",
       " 'p2_saved_by_teammate_per_round',\n",
       " 'p2_saved_teammates_per_round',\n",
       " 'p2_rating',\n",
       " 'p2_kill_death',\n",
       " 'p2_kill_round',\n",
       " 'p2_rounds_with_kills',\n",
       " 'p2_kill_death_difference',\n",
       " 'p2_total_opening_kills',\n",
       " 'p2_total_opening_deaths',\n",
       " 'p2_opening_kill_ratio',\n",
       " 'p2_opening_kill_rating',\n",
       " 'p2_team_win_percent_after_first_kill',\n",
       " 'p2_first_kill_in_won_rounds',\n",
       " 'p3_id',\n",
       " 'p3_total_kills',\n",
       " 'p3_headshots',\n",
       " 'p3_total_deaths',\n",
       " 'p3_kd_ratio',\n",
       " 'p3_damage_per_round',\n",
       " 'p3_grenade_damage_per_round',\n",
       " 'p3_maps_played',\n",
       " 'p3_rounds_played',\n",
       " 'p3_kills_per_round',\n",
       " 'p3_assists_per_round',\n",
       " 'p3_deaths_per_round',\n",
       " 'p3_saved_by_teammate_per_round',\n",
       " 'p3_saved_teammates_per_round',\n",
       " 'p3_rating',\n",
       " 'p3_kill_death',\n",
       " 'p3_kill_round',\n",
       " 'p3_rounds_with_kills',\n",
       " 'p3_kill_death_difference',\n",
       " 'p3_total_opening_kills',\n",
       " 'p3_total_opening_deaths',\n",
       " 'p3_opening_kill_ratio',\n",
       " 'p3_opening_kill_rating',\n",
       " 'p3_team_win_percent_after_first_kill',\n",
       " 'p3_first_kill_in_won_rounds',\n",
       " 'p4_id',\n",
       " 'p4_total_kills',\n",
       " 'p4_headshots',\n",
       " 'p4_total_deaths',\n",
       " 'p4_kd_ratio',\n",
       " 'p4_damage_per_round',\n",
       " 'p4_grenade_damage_per_round',\n",
       " 'p4_maps_played',\n",
       " 'p4_rounds_played',\n",
       " 'p4_kills_per_round',\n",
       " 'p4_assists_per_round',\n",
       " 'p4_deaths_per_round',\n",
       " 'p4_saved_by_teammate_per_round',\n",
       " 'p4_saved_teammates_per_round',\n",
       " 'p4_rating',\n",
       " 'p4_kill_death',\n",
       " 'p4_kill_round',\n",
       " 'p4_rounds_with_kills',\n",
       " 'p4_kill_death_difference',\n",
       " 'p4_total_opening_kills',\n",
       " 'p4_total_opening_deaths',\n",
       " 'p4_opening_kill_ratio',\n",
       " 'p4_opening_kill_rating',\n",
       " 'p4_team_win_percent_after_first_kill',\n",
       " 'p4_first_kill_in_won_rounds',\n",
       " 'p5_id',\n",
       " 'p5_total_kills',\n",
       " 'p5_headshots',\n",
       " 'p5_total_deaths',\n",
       " 'p5_kd_ratio',\n",
       " 'p5_damage_per_round',\n",
       " 'p5_grenade_damage_per_round',\n",
       " 'p5_maps_played',\n",
       " 'p5_rounds_played',\n",
       " 'p5_kills_per_round',\n",
       " 'p5_assists_per_round',\n",
       " 'p5_deaths_per_round',\n",
       " 'p5_saved_by_teammate_per_round',\n",
       " 'p5_saved_teammates_per_round',\n",
       " 'p5_rating',\n",
       " 'p5_kill_death',\n",
       " 'p5_kill_round',\n",
       " 'p5_rounds_with_kills',\n",
       " 'p5_kill_death_difference',\n",
       " 'p5_total_opening_kills',\n",
       " 'p5_total_opening_deaths',\n",
       " 'p5_opening_kill_ratio',\n",
       " 'p5_opening_kill_rating',\n",
       " 'p5_team_win_percent_after_first_kill',\n",
       " 'p5_first_kill_in_won_rounds',\n",
       " 'team_id',\n",
       " 'map_name',\n",
       " 'map_id',\n",
       " 'map_id',\n",
       " 'team1_id',\n",
       " 'team2_id',\n",
       " 'map_name',\n",
       " 'who_win']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(totall_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bab9c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [\n",
    " 'p1_total_kills',\n",
    " 'p1_headshots',\n",
    " 'p1_total_deaths',\n",
    " 'p1_kd_ratio',\n",
    " 'p1_damage_per_round',\n",
    " 'p1_grenade_damage_per_round',\n",
    " 'p1_maps_played',\n",
    " 'p1_rounds_played',\n",
    " 'p1_kills_per_round',\n",
    " 'p1_assists_per_round',\n",
    " 'p1_deaths_per_round',\n",
    " 'p1_saved_by_teammate_per_round',\n",
    " 'p1_saved_teammates_per_round',\n",
    " 'p1_rating',\n",
    " 'p1_kill_death',\n",
    " 'p1_kill_round',\n",
    " 'p1_rounds_with_kills',\n",
    " 'p1_kill_death_difference',\n",
    " 'p1_total_opening_kills',\n",
    " 'p1_total_opening_deaths',\n",
    " 'p1_opening_kill_ratio',\n",
    " 'p1_opening_kill_rating',\n",
    " 'p1_team_win_percent_after_first_kill',\n",
    " 'p1_first_kill_in_won_rounds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ee79b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_std_and_mean(df, list1, t='1'):\n",
    "    '''Функция для рассчета средних и std'''\n",
    "    for item in list1:\n",
    "        suf = item[3:]\n",
    "        list_columns = ['p{}_'.format(i)+suf for i in range(1, 6)]\n",
    "        df['t{}_'.format(t)+suf+'_mean'] = np.mean(df[list_columns].to_numpy(), axis=1)\n",
    "        df['t{}_'.format(t)+suf+'_std'] = np.std(df[list_columns].to_numpy(), axis=1)\n",
    "        for i in range(1,6):\n",
    "            df = df.drop(columns=['p{}_'.format(i)+suf])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "264398bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "totall_df2 = make_std_and_mean(totall_df, list1, t='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40e035f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "totall_df2 = totall_df2.drop(columns=['p1_id', 'p2_id', 'p3_id', 'p4_id', 'p5_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ead9418",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_3 = '''select * from \n",
    "totall_df2, players_feats\n",
    "where (totall_df2.map_id = players_feats.map_id and totall_df2.team2_id = players_feats.team_id)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfbad6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "totall_df_3 = pql.sqldf(query_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ba3b8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['team_id',\n",
       " 'map_name',\n",
       " 'map_id',\n",
       " 'team1_id',\n",
       " 'team2_id',\n",
       " 'who_win',\n",
       " 't1_total_kills_mean',\n",
       " 't1_total_kills_std',\n",
       " 't1_headshots_mean',\n",
       " 't1_headshots_std',\n",
       " 't1_total_deaths_mean',\n",
       " 't1_total_deaths_std',\n",
       " 't1_kd_ratio_mean',\n",
       " 't1_kd_ratio_std',\n",
       " 't1_damage_per_round_mean',\n",
       " 't1_damage_per_round_std',\n",
       " 't1_grenade_damage_per_round_mean',\n",
       " 't1_grenade_damage_per_round_std',\n",
       " 't1_maps_played_mean',\n",
       " 't1_maps_played_std',\n",
       " 't1_rounds_played_mean',\n",
       " 't1_rounds_played_std',\n",
       " 't1_kills_per_round_mean',\n",
       " 't1_kills_per_round_std',\n",
       " 't1_assists_per_round_mean',\n",
       " 't1_assists_per_round_std',\n",
       " 't1_deaths_per_round_mean',\n",
       " 't1_deaths_per_round_std',\n",
       " 't1_saved_by_teammate_per_round_mean',\n",
       " 't1_saved_by_teammate_per_round_std',\n",
       " 't1_saved_teammates_per_round_mean',\n",
       " 't1_saved_teammates_per_round_std',\n",
       " 't1_rating_mean',\n",
       " 't1_rating_std',\n",
       " 't1_kill_death_mean',\n",
       " 't1_kill_death_std',\n",
       " 't1_kill_round_mean',\n",
       " 't1_kill_round_std',\n",
       " 't1_rounds_with_kills_mean',\n",
       " 't1_rounds_with_kills_std',\n",
       " 't1_kill_death_difference_mean',\n",
       " 't1_kill_death_difference_std',\n",
       " 't1_total_opening_kills_mean',\n",
       " 't1_total_opening_kills_std',\n",
       " 't1_total_opening_deaths_mean',\n",
       " 't1_total_opening_deaths_std',\n",
       " 't1_opening_kill_ratio_mean',\n",
       " 't1_opening_kill_ratio_std',\n",
       " 't1_opening_kill_rating_mean',\n",
       " 't1_opening_kill_rating_std',\n",
       " 't1_team_win_percent_after_first_kill_mean',\n",
       " 't1_team_win_percent_after_first_kill_std',\n",
       " 't1_first_kill_in_won_rounds_mean',\n",
       " 't1_first_kill_in_won_rounds_std',\n",
       " 'p1_id',\n",
       " 'p1_total_kills',\n",
       " 'p1_headshots',\n",
       " 'p1_total_deaths',\n",
       " 'p1_kd_ratio',\n",
       " 'p1_damage_per_round',\n",
       " 'p1_grenade_damage_per_round',\n",
       " 'p1_maps_played',\n",
       " 'p1_rounds_played',\n",
       " 'p1_kills_per_round',\n",
       " 'p1_assists_per_round',\n",
       " 'p1_deaths_per_round',\n",
       " 'p1_saved_by_teammate_per_round',\n",
       " 'p1_saved_teammates_per_round',\n",
       " 'p1_rating',\n",
       " 'p1_kill_death',\n",
       " 'p1_kill_round',\n",
       " 'p1_rounds_with_kills',\n",
       " 'p1_kill_death_difference',\n",
       " 'p1_total_opening_kills',\n",
       " 'p1_total_opening_deaths',\n",
       " 'p1_opening_kill_ratio',\n",
       " 'p1_opening_kill_rating',\n",
       " 'p1_team_win_percent_after_first_kill',\n",
       " 'p1_first_kill_in_won_rounds',\n",
       " 'p2_id',\n",
       " 'p2_total_kills',\n",
       " 'p2_headshots',\n",
       " 'p2_total_deaths',\n",
       " 'p2_kd_ratio',\n",
       " 'p2_damage_per_round',\n",
       " 'p2_grenade_damage_per_round',\n",
       " 'p2_maps_played',\n",
       " 'p2_rounds_played',\n",
       " 'p2_kills_per_round',\n",
       " 'p2_assists_per_round',\n",
       " 'p2_deaths_per_round',\n",
       " 'p2_saved_by_teammate_per_round',\n",
       " 'p2_saved_teammates_per_round',\n",
       " 'p2_rating',\n",
       " 'p2_kill_death',\n",
       " 'p2_kill_round',\n",
       " 'p2_rounds_with_kills',\n",
       " 'p2_kill_death_difference',\n",
       " 'p2_total_opening_kills',\n",
       " 'p2_total_opening_deaths',\n",
       " 'p2_opening_kill_ratio',\n",
       " 'p2_opening_kill_rating',\n",
       " 'p2_team_win_percent_after_first_kill',\n",
       " 'p2_first_kill_in_won_rounds',\n",
       " 'p3_id',\n",
       " 'p3_total_kills',\n",
       " 'p3_headshots',\n",
       " 'p3_total_deaths',\n",
       " 'p3_kd_ratio',\n",
       " 'p3_damage_per_round',\n",
       " 'p3_grenade_damage_per_round',\n",
       " 'p3_maps_played',\n",
       " 'p3_rounds_played',\n",
       " 'p3_kills_per_round',\n",
       " 'p3_assists_per_round',\n",
       " 'p3_deaths_per_round',\n",
       " 'p3_saved_by_teammate_per_round',\n",
       " 'p3_saved_teammates_per_round',\n",
       " 'p3_rating',\n",
       " 'p3_kill_death',\n",
       " 'p3_kill_round',\n",
       " 'p3_rounds_with_kills',\n",
       " 'p3_kill_death_difference',\n",
       " 'p3_total_opening_kills',\n",
       " 'p3_total_opening_deaths',\n",
       " 'p3_opening_kill_ratio',\n",
       " 'p3_opening_kill_rating',\n",
       " 'p3_team_win_percent_after_first_kill',\n",
       " 'p3_first_kill_in_won_rounds',\n",
       " 'p4_id',\n",
       " 'p4_total_kills',\n",
       " 'p4_headshots',\n",
       " 'p4_total_deaths',\n",
       " 'p4_kd_ratio',\n",
       " 'p4_damage_per_round',\n",
       " 'p4_grenade_damage_per_round',\n",
       " 'p4_maps_played',\n",
       " 'p4_rounds_played',\n",
       " 'p4_kills_per_round',\n",
       " 'p4_assists_per_round',\n",
       " 'p4_deaths_per_round',\n",
       " 'p4_saved_by_teammate_per_round',\n",
       " 'p4_saved_teammates_per_round',\n",
       " 'p4_rating',\n",
       " 'p4_kill_death',\n",
       " 'p4_kill_round',\n",
       " 'p4_rounds_with_kills',\n",
       " 'p4_kill_death_difference',\n",
       " 'p4_total_opening_kills',\n",
       " 'p4_total_opening_deaths',\n",
       " 'p4_opening_kill_ratio',\n",
       " 'p4_opening_kill_rating',\n",
       " 'p4_team_win_percent_after_first_kill',\n",
       " 'p4_first_kill_in_won_rounds',\n",
       " 'p5_id',\n",
       " 'p5_total_kills',\n",
       " 'p5_headshots',\n",
       " 'p5_total_deaths',\n",
       " 'p5_kd_ratio',\n",
       " 'p5_damage_per_round',\n",
       " 'p5_grenade_damage_per_round',\n",
       " 'p5_maps_played',\n",
       " 'p5_rounds_played',\n",
       " 'p5_kills_per_round',\n",
       " 'p5_assists_per_round',\n",
       " 'p5_deaths_per_round',\n",
       " 'p5_saved_by_teammate_per_round',\n",
       " 'p5_saved_teammates_per_round',\n",
       " 'p5_rating',\n",
       " 'p5_kill_death',\n",
       " 'p5_kill_round',\n",
       " 'p5_rounds_with_kills',\n",
       " 'p5_kill_death_difference',\n",
       " 'p5_total_opening_kills',\n",
       " 'p5_total_opening_deaths',\n",
       " 'p5_opening_kill_ratio',\n",
       " 'p5_opening_kill_rating',\n",
       " 'p5_team_win_percent_after_first_kill',\n",
       " 'p5_first_kill_in_won_rounds',\n",
       " 'team_id',\n",
       " 'map_name',\n",
       " 'map_id']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(totall_df_3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef5c9ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "totall_df_3 = totall_df_3.drop(columns=['p1_id', 'p2_id', 'p3_id', 'p4_id', 'p5_id', 'team_id',\n",
    " 'map_name'])\n",
    "#  'map_id',\n",
    "# 'team1_id',\n",
    "#  'team2_id',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f24903b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['map_id',\n",
       " 'team1_id',\n",
       " 'team2_id',\n",
       " 'who_win',\n",
       " 't1_total_kills_mean',\n",
       " 't1_total_kills_std',\n",
       " 't1_headshots_mean',\n",
       " 't1_headshots_std',\n",
       " 't1_total_deaths_mean',\n",
       " 't1_total_deaths_std',\n",
       " 't1_kd_ratio_mean',\n",
       " 't1_kd_ratio_std',\n",
       " 't1_damage_per_round_mean',\n",
       " 't1_damage_per_round_std',\n",
       " 't1_grenade_damage_per_round_mean',\n",
       " 't1_grenade_damage_per_round_std',\n",
       " 't1_maps_played_mean',\n",
       " 't1_maps_played_std',\n",
       " 't1_rounds_played_mean',\n",
       " 't1_rounds_played_std',\n",
       " 't1_kills_per_round_mean',\n",
       " 't1_kills_per_round_std',\n",
       " 't1_assists_per_round_mean',\n",
       " 't1_assists_per_round_std',\n",
       " 't1_deaths_per_round_mean',\n",
       " 't1_deaths_per_round_std',\n",
       " 't1_saved_by_teammate_per_round_mean',\n",
       " 't1_saved_by_teammate_per_round_std',\n",
       " 't1_saved_teammates_per_round_mean',\n",
       " 't1_saved_teammates_per_round_std',\n",
       " 't1_rating_mean',\n",
       " 't1_rating_std',\n",
       " 't1_kill_death_mean',\n",
       " 't1_kill_death_std',\n",
       " 't1_kill_round_mean',\n",
       " 't1_kill_round_std',\n",
       " 't1_rounds_with_kills_mean',\n",
       " 't1_rounds_with_kills_std',\n",
       " 't1_kill_death_difference_mean',\n",
       " 't1_kill_death_difference_std',\n",
       " 't1_total_opening_kills_mean',\n",
       " 't1_total_opening_kills_std',\n",
       " 't1_total_opening_deaths_mean',\n",
       " 't1_total_opening_deaths_std',\n",
       " 't1_opening_kill_ratio_mean',\n",
       " 't1_opening_kill_ratio_std',\n",
       " 't1_opening_kill_rating_mean',\n",
       " 't1_opening_kill_rating_std',\n",
       " 't1_team_win_percent_after_first_kill_mean',\n",
       " 't1_team_win_percent_after_first_kill_std',\n",
       " 't1_first_kill_in_won_rounds_mean',\n",
       " 't1_first_kill_in_won_rounds_std',\n",
       " 'p1_total_kills',\n",
       " 'p1_headshots',\n",
       " 'p1_total_deaths',\n",
       " 'p1_kd_ratio',\n",
       " 'p1_damage_per_round',\n",
       " 'p1_grenade_damage_per_round',\n",
       " 'p1_maps_played',\n",
       " 'p1_rounds_played',\n",
       " 'p1_kills_per_round',\n",
       " 'p1_assists_per_round',\n",
       " 'p1_deaths_per_round',\n",
       " 'p1_saved_by_teammate_per_round',\n",
       " 'p1_saved_teammates_per_round',\n",
       " 'p1_rating',\n",
       " 'p1_kill_death',\n",
       " 'p1_kill_round',\n",
       " 'p1_rounds_with_kills',\n",
       " 'p1_kill_death_difference',\n",
       " 'p1_total_opening_kills',\n",
       " 'p1_total_opening_deaths',\n",
       " 'p1_opening_kill_ratio',\n",
       " 'p1_opening_kill_rating',\n",
       " 'p1_team_win_percent_after_first_kill',\n",
       " 'p1_first_kill_in_won_rounds',\n",
       " 'p2_total_kills',\n",
       " 'p2_headshots',\n",
       " 'p2_total_deaths',\n",
       " 'p2_kd_ratio',\n",
       " 'p2_damage_per_round',\n",
       " 'p2_grenade_damage_per_round',\n",
       " 'p2_maps_played',\n",
       " 'p2_rounds_played',\n",
       " 'p2_kills_per_round',\n",
       " 'p2_assists_per_round',\n",
       " 'p2_deaths_per_round',\n",
       " 'p2_saved_by_teammate_per_round',\n",
       " 'p2_saved_teammates_per_round',\n",
       " 'p2_rating',\n",
       " 'p2_kill_death',\n",
       " 'p2_kill_round',\n",
       " 'p2_rounds_with_kills',\n",
       " 'p2_kill_death_difference',\n",
       " 'p2_total_opening_kills',\n",
       " 'p2_total_opening_deaths',\n",
       " 'p2_opening_kill_ratio',\n",
       " 'p2_opening_kill_rating',\n",
       " 'p2_team_win_percent_after_first_kill',\n",
       " 'p2_first_kill_in_won_rounds',\n",
       " 'p3_total_kills',\n",
       " 'p3_headshots',\n",
       " 'p3_total_deaths',\n",
       " 'p3_kd_ratio',\n",
       " 'p3_damage_per_round',\n",
       " 'p3_grenade_damage_per_round',\n",
       " 'p3_maps_played',\n",
       " 'p3_rounds_played',\n",
       " 'p3_kills_per_round',\n",
       " 'p3_assists_per_round',\n",
       " 'p3_deaths_per_round',\n",
       " 'p3_saved_by_teammate_per_round',\n",
       " 'p3_saved_teammates_per_round',\n",
       " 'p3_rating',\n",
       " 'p3_kill_death',\n",
       " 'p3_kill_round',\n",
       " 'p3_rounds_with_kills',\n",
       " 'p3_kill_death_difference',\n",
       " 'p3_total_opening_kills',\n",
       " 'p3_total_opening_deaths',\n",
       " 'p3_opening_kill_ratio',\n",
       " 'p3_opening_kill_rating',\n",
       " 'p3_team_win_percent_after_first_kill',\n",
       " 'p3_first_kill_in_won_rounds',\n",
       " 'p4_total_kills',\n",
       " 'p4_headshots',\n",
       " 'p4_total_deaths',\n",
       " 'p4_kd_ratio',\n",
       " 'p4_damage_per_round',\n",
       " 'p4_grenade_damage_per_round',\n",
       " 'p4_maps_played',\n",
       " 'p4_rounds_played',\n",
       " 'p4_kills_per_round',\n",
       " 'p4_assists_per_round',\n",
       " 'p4_deaths_per_round',\n",
       " 'p4_saved_by_teammate_per_round',\n",
       " 'p4_saved_teammates_per_round',\n",
       " 'p4_rating',\n",
       " 'p4_kill_death',\n",
       " 'p4_kill_round',\n",
       " 'p4_rounds_with_kills',\n",
       " 'p4_kill_death_difference',\n",
       " 'p4_total_opening_kills',\n",
       " 'p4_total_opening_deaths',\n",
       " 'p4_opening_kill_ratio',\n",
       " 'p4_opening_kill_rating',\n",
       " 'p4_team_win_percent_after_first_kill',\n",
       " 'p4_first_kill_in_won_rounds',\n",
       " 'p5_total_kills',\n",
       " 'p5_headshots',\n",
       " 'p5_total_deaths',\n",
       " 'p5_kd_ratio',\n",
       " 'p5_damage_per_round',\n",
       " 'p5_grenade_damage_per_round',\n",
       " 'p5_maps_played',\n",
       " 'p5_rounds_played',\n",
       " 'p5_kills_per_round',\n",
       " 'p5_assists_per_round',\n",
       " 'p5_deaths_per_round',\n",
       " 'p5_saved_by_teammate_per_round',\n",
       " 'p5_saved_teammates_per_round',\n",
       " 'p5_rating',\n",
       " 'p5_kill_death',\n",
       " 'p5_kill_round',\n",
       " 'p5_rounds_with_kills',\n",
       " 'p5_kill_death_difference',\n",
       " 'p5_total_opening_kills',\n",
       " 'p5_total_opening_deaths',\n",
       " 'p5_opening_kill_ratio',\n",
       " 'p5_opening_kill_rating',\n",
       " 'p5_team_win_percent_after_first_kill',\n",
       " 'p5_first_kill_in_won_rounds',\n",
       " 'map_id']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(totall_df_3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "292e4060",
   "metadata": {},
   "outputs": [],
   "source": [
    "totall_df_3 = totall_df_3.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02da662b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "totall_df_4 = make_std_and_mean(totall_df_3, list1, t='2')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4c0bbb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>map_id</th>\n",
       "      <th>team1_id</th>\n",
       "      <th>team2_id</th>\n",
       "      <th>who_win</th>\n",
       "      <th>t1_total_kills_mean</th>\n",
       "      <th>t1_total_kills_std</th>\n",
       "      <th>t1_headshots_mean</th>\n",
       "      <th>t1_headshots_std</th>\n",
       "      <th>t1_total_deaths_mean</th>\n",
       "      <th>t1_total_deaths_std</th>\n",
       "      <th>...</th>\n",
       "      <th>t2_total_opening_deaths_mean</th>\n",
       "      <th>t2_total_opening_deaths_std</th>\n",
       "      <th>t2_opening_kill_ratio_mean</th>\n",
       "      <th>t2_opening_kill_ratio_std</th>\n",
       "      <th>t2_opening_kill_rating_mean</th>\n",
       "      <th>t2_opening_kill_rating_std</th>\n",
       "      <th>t2_team_win_percent_after_first_kill_mean</th>\n",
       "      <th>t2_team_win_percent_after_first_kill_std</th>\n",
       "      <th>t2_first_kill_in_won_rounds_mean</th>\n",
       "      <th>t2_first_kill_in_won_rounds_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>635</td>\n",
       "      <td>6665</td>\n",
       "      <td>7532</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.4</td>\n",
       "      <td>30.787010</td>\n",
       "      <td>44.96</td>\n",
       "      <td>10.351927</td>\n",
       "      <td>111.4</td>\n",
       "      <td>30.269457</td>\n",
       "      <td>...</td>\n",
       "      <td>13.8</td>\n",
       "      <td>10.514752</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.425986</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.128468</td>\n",
       "      <td>50.16</td>\n",
       "      <td>28.897515</td>\n",
       "      <td>14.34</td>\n",
       "      <td>8.668472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>583</td>\n",
       "      <td>6665</td>\n",
       "      <td>7532</td>\n",
       "      <td>1.0</td>\n",
       "      <td>139.2</td>\n",
       "      <td>37.252651</td>\n",
       "      <td>41.70</td>\n",
       "      <td>7.852898</td>\n",
       "      <td>138.6</td>\n",
       "      <td>32.450578</td>\n",
       "      <td>...</td>\n",
       "      <td>59.2</td>\n",
       "      <td>8.885944</td>\n",
       "      <td>1.096</td>\n",
       "      <td>0.377815</td>\n",
       "      <td>1.036</td>\n",
       "      <td>0.157556</td>\n",
       "      <td>77.56</td>\n",
       "      <td>6.753547</td>\n",
       "      <td>16.14</td>\n",
       "      <td>5.309840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>439</td>\n",
       "      <td>4608</td>\n",
       "      <td>9215</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160.2</td>\n",
       "      <td>10.998182</td>\n",
       "      <td>49.44</td>\n",
       "      <td>11.350348</td>\n",
       "      <td>125.2</td>\n",
       "      <td>7.249828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.897367</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.895893</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.538791</td>\n",
       "      <td>53.14</td>\n",
       "      <td>43.875260</td>\n",
       "      <td>10.40</td>\n",
       "      <td>9.329523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>363</td>\n",
       "      <td>5995</td>\n",
       "      <td>4411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>316.2</td>\n",
       "      <td>103.933440</td>\n",
       "      <td>46.80</td>\n",
       "      <td>10.648568</td>\n",
       "      <td>289.0</td>\n",
       "      <td>94.935768</td>\n",
       "      <td>...</td>\n",
       "      <td>28.8</td>\n",
       "      <td>8.840814</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.214252</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.149131</td>\n",
       "      <td>64.44</td>\n",
       "      <td>5.683872</td>\n",
       "      <td>13.12</td>\n",
       "      <td>4.507061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>4608</td>\n",
       "      <td>6665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>268.6</td>\n",
       "      <td>59.156065</td>\n",
       "      <td>46.94</td>\n",
       "      <td>10.264814</td>\n",
       "      <td>238.2</td>\n",
       "      <td>14.878172</td>\n",
       "      <td>...</td>\n",
       "      <td>29.6</td>\n",
       "      <td>13.001538</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.210580</td>\n",
       "      <td>1.010</td>\n",
       "      <td>0.154013</td>\n",
       "      <td>69.20</td>\n",
       "      <td>2.916162</td>\n",
       "      <td>15.02</td>\n",
       "      <td>6.225560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>357</td>\n",
       "      <td>4608</td>\n",
       "      <td>6667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>442.0</td>\n",
       "      <td>83.744851</td>\n",
       "      <td>47.08</td>\n",
       "      <td>9.787012</td>\n",
       "      <td>393.4</td>\n",
       "      <td>25.896718</td>\n",
       "      <td>...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20.069878</td>\n",
       "      <td>1.064</td>\n",
       "      <td>0.520715</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.111427</td>\n",
       "      <td>76.60</td>\n",
       "      <td>7.071916</td>\n",
       "      <td>13.94</td>\n",
       "      <td>3.283656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>593</td>\n",
       "      <td>4608</td>\n",
       "      <td>6667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>213.6</td>\n",
       "      <td>31.283222</td>\n",
       "      <td>52.44</td>\n",
       "      <td>7.730873</td>\n",
       "      <td>194.4</td>\n",
       "      <td>13.001538</td>\n",
       "      <td>...</td>\n",
       "      <td>32.4</td>\n",
       "      <td>13.215143</td>\n",
       "      <td>1.488</td>\n",
       "      <td>0.349651</td>\n",
       "      <td>1.110</td>\n",
       "      <td>0.123612</td>\n",
       "      <td>78.58</td>\n",
       "      <td>3.946847</td>\n",
       "      <td>15.04</td>\n",
       "      <td>4.237263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>284</td>\n",
       "      <td>6665</td>\n",
       "      <td>10503</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.2</td>\n",
       "      <td>30.353912</td>\n",
       "      <td>43.68</td>\n",
       "      <td>8.210091</td>\n",
       "      <td>92.8</td>\n",
       "      <td>30.694625</td>\n",
       "      <td>...</td>\n",
       "      <td>11.2</td>\n",
       "      <td>3.544009</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.498518</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.175271</td>\n",
       "      <td>81.90</td>\n",
       "      <td>10.629017</td>\n",
       "      <td>14.68</td>\n",
       "      <td>4.787233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>27</td>\n",
       "      <td>7020</td>\n",
       "      <td>8297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114.6</td>\n",
       "      <td>13.078226</td>\n",
       "      <td>48.76</td>\n",
       "      <td>5.701438</td>\n",
       "      <td>110.6</td>\n",
       "      <td>10.965400</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.757049</td>\n",
       "      <td>1.076</td>\n",
       "      <td>0.295337</td>\n",
       "      <td>1.016</td>\n",
       "      <td>0.167404</td>\n",
       "      <td>70.62</td>\n",
       "      <td>10.617796</td>\n",
       "      <td>12.70</td>\n",
       "      <td>6.680120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>237</td>\n",
       "      <td>7020</td>\n",
       "      <td>8297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>205.4</td>\n",
       "      <td>42.659583</td>\n",
       "      <td>46.82</td>\n",
       "      <td>8.237330</td>\n",
       "      <td>161.2</td>\n",
       "      <td>29.532355</td>\n",
       "      <td>...</td>\n",
       "      <td>18.4</td>\n",
       "      <td>6.651316</td>\n",
       "      <td>1.280</td>\n",
       "      <td>0.333407</td>\n",
       "      <td>1.066</td>\n",
       "      <td>0.095205</td>\n",
       "      <td>78.98</td>\n",
       "      <td>5.913172</td>\n",
       "      <td>15.24</td>\n",
       "      <td>4.274857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>727 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     map_id  team1_id  team2_id  who_win  t1_total_kills_mean  \\\n",
       "0       635      6665      7532      1.0                 98.4   \n",
       "1       583      6665      7532      1.0                139.2   \n",
       "2       439      4608      9215      1.0                160.2   \n",
       "3       363      5995      4411      0.0                316.2   \n",
       "4       105      4608      6665      1.0                268.6   \n",
       "..      ...       ...       ...      ...                  ...   \n",
       "722     357      4608      6667      NaN                442.0   \n",
       "723     593      4608      6667      NaN                213.6   \n",
       "724     284      6665     10503      1.0                 86.2   \n",
       "725      27      7020      8297      0.0                114.6   \n",
       "726     237      7020      8297      0.0                205.4   \n",
       "\n",
       "     t1_total_kills_std  t1_headshots_mean  t1_headshots_std  \\\n",
       "0             30.787010              44.96         10.351927   \n",
       "1             37.252651              41.70          7.852898   \n",
       "2             10.998182              49.44         11.350348   \n",
       "3            103.933440              46.80         10.648568   \n",
       "4             59.156065              46.94         10.264814   \n",
       "..                  ...                ...               ...   \n",
       "722           83.744851              47.08          9.787012   \n",
       "723           31.283222              52.44          7.730873   \n",
       "724           30.353912              43.68          8.210091   \n",
       "725           13.078226              48.76          5.701438   \n",
       "726           42.659583              46.82          8.237330   \n",
       "\n",
       "     t1_total_deaths_mean  t1_total_deaths_std  ...  \\\n",
       "0                   111.4            30.269457  ...   \n",
       "1                   138.6            32.450578  ...   \n",
       "2                   125.2             7.249828  ...   \n",
       "3                   289.0            94.935768  ...   \n",
       "4                   238.2            14.878172  ...   \n",
       "..                    ...                  ...  ...   \n",
       "722                 393.4            25.896718  ...   \n",
       "723                 194.4            13.001538  ...   \n",
       "724                  92.8            30.694625  ...   \n",
       "725                 110.6            10.965400  ...   \n",
       "726                 161.2            29.532355  ...   \n",
       "\n",
       "     t2_total_opening_deaths_mean  t2_total_opening_deaths_std  \\\n",
       "0                            13.8                    10.514752   \n",
       "1                            59.2                     8.885944   \n",
       "2                             2.0                     1.897367   \n",
       "3                            28.8                     8.840814   \n",
       "4                            29.6                    13.001538   \n",
       "..                            ...                          ...   \n",
       "722                          57.0                    20.069878   \n",
       "723                          32.4                    13.215143   \n",
       "724                          11.2                     3.544009   \n",
       "725                          20.0                     9.757049   \n",
       "726                          18.4                     6.651316   \n",
       "\n",
       "     t2_opening_kill_ratio_mean  t2_opening_kill_ratio_std  \\\n",
       "0                         0.926                   0.425986   \n",
       "1                         1.096                   0.377815   \n",
       "2                         0.966                   0.895893   \n",
       "3                         0.814                   0.214252   \n",
       "4                         0.994                   0.210580   \n",
       "..                          ...                        ...   \n",
       "722                       1.064                   0.520715   \n",
       "723                       1.488                   0.349651   \n",
       "724                       1.040                   0.498518   \n",
       "725                       1.076                   0.295337   \n",
       "726                       1.280                   0.333407   \n",
       "\n",
       "     t2_opening_kill_rating_mean  t2_opening_kill_rating_std  \\\n",
       "0                          0.934                    0.128468   \n",
       "1                          1.036                    0.157556   \n",
       "2                          0.642                    0.538791   \n",
       "3                          0.940                    0.149131   \n",
       "4                          1.010                    0.154013   \n",
       "..                           ...                         ...   \n",
       "722                        0.968                    0.111427   \n",
       "723                        1.110                    0.123612   \n",
       "724                        0.980                    0.175271   \n",
       "725                        1.016                    0.167404   \n",
       "726                        1.066                    0.095205   \n",
       "\n",
       "     t2_team_win_percent_after_first_kill_mean  \\\n",
       "0                                        50.16   \n",
       "1                                        77.56   \n",
       "2                                        53.14   \n",
       "3                                        64.44   \n",
       "4                                        69.20   \n",
       "..                                         ...   \n",
       "722                                      76.60   \n",
       "723                                      78.58   \n",
       "724                                      81.90   \n",
       "725                                      70.62   \n",
       "726                                      78.98   \n",
       "\n",
       "     t2_team_win_percent_after_first_kill_std  \\\n",
       "0                                   28.897515   \n",
       "1                                    6.753547   \n",
       "2                                   43.875260   \n",
       "3                                    5.683872   \n",
       "4                                    2.916162   \n",
       "..                                        ...   \n",
       "722                                  7.071916   \n",
       "723                                  3.946847   \n",
       "724                                 10.629017   \n",
       "725                                 10.617796   \n",
       "726                                  5.913172   \n",
       "\n",
       "     t2_first_kill_in_won_rounds_mean  t2_first_kill_in_won_rounds_std  \n",
       "0                               14.34                         8.668472  \n",
       "1                               16.14                         5.309840  \n",
       "2                               10.40                         9.329523  \n",
       "3                               13.12                         4.507061  \n",
       "4                               15.02                         6.225560  \n",
       "..                                ...                              ...  \n",
       "722                             13.94                         3.283656  \n",
       "723                             15.04                         4.237263  \n",
       "724                             14.68                         4.787233  \n",
       "725                             12.70                         6.680120  \n",
       "726                             15.24                         4.274857  \n",
       "\n",
       "[727 rows x 100 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totall_df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfb54638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>map_id</th>\n",
       "      <th>team1_id</th>\n",
       "      <th>team2_id</th>\n",
       "      <th>who_win</th>\n",
       "      <th>t1_total_kills_mean</th>\n",
       "      <th>t1_total_kills_std</th>\n",
       "      <th>t1_headshots_mean</th>\n",
       "      <th>t1_headshots_std</th>\n",
       "      <th>t1_total_deaths_mean</th>\n",
       "      <th>t1_total_deaths_std</th>\n",
       "      <th>...</th>\n",
       "      <th>t2_total_opening_deaths_mean</th>\n",
       "      <th>t2_total_opening_deaths_std</th>\n",
       "      <th>t2_opening_kill_ratio_mean</th>\n",
       "      <th>t2_opening_kill_ratio_std</th>\n",
       "      <th>t2_opening_kill_rating_mean</th>\n",
       "      <th>t2_opening_kill_rating_std</th>\n",
       "      <th>t2_team_win_percent_after_first_kill_mean</th>\n",
       "      <th>t2_team_win_percent_after_first_kill_std</th>\n",
       "      <th>t2_first_kill_in_won_rounds_mean</th>\n",
       "      <th>t2_first_kill_in_won_rounds_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>635</td>\n",
       "      <td>6665</td>\n",
       "      <td>7532</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.4</td>\n",
       "      <td>30.787010</td>\n",
       "      <td>44.96</td>\n",
       "      <td>10.351927</td>\n",
       "      <td>111.4</td>\n",
       "      <td>30.269457</td>\n",
       "      <td>...</td>\n",
       "      <td>13.8</td>\n",
       "      <td>10.514752</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.425986</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.128468</td>\n",
       "      <td>50.16</td>\n",
       "      <td>28.897515</td>\n",
       "      <td>14.34</td>\n",
       "      <td>8.668472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>583</td>\n",
       "      <td>6665</td>\n",
       "      <td>7532</td>\n",
       "      <td>1.0</td>\n",
       "      <td>139.2</td>\n",
       "      <td>37.252651</td>\n",
       "      <td>41.70</td>\n",
       "      <td>7.852898</td>\n",
       "      <td>138.6</td>\n",
       "      <td>32.450578</td>\n",
       "      <td>...</td>\n",
       "      <td>59.2</td>\n",
       "      <td>8.885944</td>\n",
       "      <td>1.096</td>\n",
       "      <td>0.377815</td>\n",
       "      <td>1.036</td>\n",
       "      <td>0.157556</td>\n",
       "      <td>77.56</td>\n",
       "      <td>6.753547</td>\n",
       "      <td>16.14</td>\n",
       "      <td>5.309840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>439</td>\n",
       "      <td>4608</td>\n",
       "      <td>9215</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160.2</td>\n",
       "      <td>10.998182</td>\n",
       "      <td>49.44</td>\n",
       "      <td>11.350348</td>\n",
       "      <td>125.2</td>\n",
       "      <td>7.249828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.897367</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.895893</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.538791</td>\n",
       "      <td>53.14</td>\n",
       "      <td>43.875260</td>\n",
       "      <td>10.40</td>\n",
       "      <td>9.329523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>363</td>\n",
       "      <td>5995</td>\n",
       "      <td>4411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>316.2</td>\n",
       "      <td>103.933440</td>\n",
       "      <td>46.80</td>\n",
       "      <td>10.648568</td>\n",
       "      <td>289.0</td>\n",
       "      <td>94.935768</td>\n",
       "      <td>...</td>\n",
       "      <td>28.8</td>\n",
       "      <td>8.840814</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.214252</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.149131</td>\n",
       "      <td>64.44</td>\n",
       "      <td>5.683872</td>\n",
       "      <td>13.12</td>\n",
       "      <td>4.507061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>4608</td>\n",
       "      <td>6665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>268.6</td>\n",
       "      <td>59.156065</td>\n",
       "      <td>46.94</td>\n",
       "      <td>10.264814</td>\n",
       "      <td>238.2</td>\n",
       "      <td>14.878172</td>\n",
       "      <td>...</td>\n",
       "      <td>29.6</td>\n",
       "      <td>13.001538</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.210580</td>\n",
       "      <td>1.010</td>\n",
       "      <td>0.154013</td>\n",
       "      <td>69.20</td>\n",
       "      <td>2.916162</td>\n",
       "      <td>15.02</td>\n",
       "      <td>6.225560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>357</td>\n",
       "      <td>4608</td>\n",
       "      <td>6667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>442.0</td>\n",
       "      <td>83.744851</td>\n",
       "      <td>47.08</td>\n",
       "      <td>9.787012</td>\n",
       "      <td>393.4</td>\n",
       "      <td>25.896718</td>\n",
       "      <td>...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20.069878</td>\n",
       "      <td>1.064</td>\n",
       "      <td>0.520715</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.111427</td>\n",
       "      <td>76.60</td>\n",
       "      <td>7.071916</td>\n",
       "      <td>13.94</td>\n",
       "      <td>3.283656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>593</td>\n",
       "      <td>4608</td>\n",
       "      <td>6667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>213.6</td>\n",
       "      <td>31.283222</td>\n",
       "      <td>52.44</td>\n",
       "      <td>7.730873</td>\n",
       "      <td>194.4</td>\n",
       "      <td>13.001538</td>\n",
       "      <td>...</td>\n",
       "      <td>32.4</td>\n",
       "      <td>13.215143</td>\n",
       "      <td>1.488</td>\n",
       "      <td>0.349651</td>\n",
       "      <td>1.110</td>\n",
       "      <td>0.123612</td>\n",
       "      <td>78.58</td>\n",
       "      <td>3.946847</td>\n",
       "      <td>15.04</td>\n",
       "      <td>4.237263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>284</td>\n",
       "      <td>6665</td>\n",
       "      <td>10503</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.2</td>\n",
       "      <td>30.353912</td>\n",
       "      <td>43.68</td>\n",
       "      <td>8.210091</td>\n",
       "      <td>92.8</td>\n",
       "      <td>30.694625</td>\n",
       "      <td>...</td>\n",
       "      <td>11.2</td>\n",
       "      <td>3.544009</td>\n",
       "      <td>1.040</td>\n",
       "      <td>0.498518</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.175271</td>\n",
       "      <td>81.90</td>\n",
       "      <td>10.629017</td>\n",
       "      <td>14.68</td>\n",
       "      <td>4.787233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>27</td>\n",
       "      <td>7020</td>\n",
       "      <td>8297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114.6</td>\n",
       "      <td>13.078226</td>\n",
       "      <td>48.76</td>\n",
       "      <td>5.701438</td>\n",
       "      <td>110.6</td>\n",
       "      <td>10.965400</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.757049</td>\n",
       "      <td>1.076</td>\n",
       "      <td>0.295337</td>\n",
       "      <td>1.016</td>\n",
       "      <td>0.167404</td>\n",
       "      <td>70.62</td>\n",
       "      <td>10.617796</td>\n",
       "      <td>12.70</td>\n",
       "      <td>6.680120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>237</td>\n",
       "      <td>7020</td>\n",
       "      <td>8297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>205.4</td>\n",
       "      <td>42.659583</td>\n",
       "      <td>46.82</td>\n",
       "      <td>8.237330</td>\n",
       "      <td>161.2</td>\n",
       "      <td>29.532355</td>\n",
       "      <td>...</td>\n",
       "      <td>18.4</td>\n",
       "      <td>6.651316</td>\n",
       "      <td>1.280</td>\n",
       "      <td>0.333407</td>\n",
       "      <td>1.066</td>\n",
       "      <td>0.095205</td>\n",
       "      <td>78.98</td>\n",
       "      <td>5.913172</td>\n",
       "      <td>15.24</td>\n",
       "      <td>4.274857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>727 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     map_id  team1_id  team2_id  who_win  t1_total_kills_mean  \\\n",
       "0       635      6665      7532      1.0                 98.4   \n",
       "1       583      6665      7532      1.0                139.2   \n",
       "2       439      4608      9215      1.0                160.2   \n",
       "3       363      5995      4411      0.0                316.2   \n",
       "4       105      4608      6665      1.0                268.6   \n",
       "..      ...       ...       ...      ...                  ...   \n",
       "722     357      4608      6667      NaN                442.0   \n",
       "723     593      4608      6667      NaN                213.6   \n",
       "724     284      6665     10503      1.0                 86.2   \n",
       "725      27      7020      8297      0.0                114.6   \n",
       "726     237      7020      8297      0.0                205.4   \n",
       "\n",
       "     t1_total_kills_std  t1_headshots_mean  t1_headshots_std  \\\n",
       "0             30.787010              44.96         10.351927   \n",
       "1             37.252651              41.70          7.852898   \n",
       "2             10.998182              49.44         11.350348   \n",
       "3            103.933440              46.80         10.648568   \n",
       "4             59.156065              46.94         10.264814   \n",
       "..                  ...                ...               ...   \n",
       "722           83.744851              47.08          9.787012   \n",
       "723           31.283222              52.44          7.730873   \n",
       "724           30.353912              43.68          8.210091   \n",
       "725           13.078226              48.76          5.701438   \n",
       "726           42.659583              46.82          8.237330   \n",
       "\n",
       "     t1_total_deaths_mean  t1_total_deaths_std  ...  \\\n",
       "0                   111.4            30.269457  ...   \n",
       "1                   138.6            32.450578  ...   \n",
       "2                   125.2             7.249828  ...   \n",
       "3                   289.0            94.935768  ...   \n",
       "4                   238.2            14.878172  ...   \n",
       "..                    ...                  ...  ...   \n",
       "722                 393.4            25.896718  ...   \n",
       "723                 194.4            13.001538  ...   \n",
       "724                  92.8            30.694625  ...   \n",
       "725                 110.6            10.965400  ...   \n",
       "726                 161.2            29.532355  ...   \n",
       "\n",
       "     t2_total_opening_deaths_mean  t2_total_opening_deaths_std  \\\n",
       "0                            13.8                    10.514752   \n",
       "1                            59.2                     8.885944   \n",
       "2                             2.0                     1.897367   \n",
       "3                            28.8                     8.840814   \n",
       "4                            29.6                    13.001538   \n",
       "..                            ...                          ...   \n",
       "722                          57.0                    20.069878   \n",
       "723                          32.4                    13.215143   \n",
       "724                          11.2                     3.544009   \n",
       "725                          20.0                     9.757049   \n",
       "726                          18.4                     6.651316   \n",
       "\n",
       "     t2_opening_kill_ratio_mean  t2_opening_kill_ratio_std  \\\n",
       "0                         0.926                   0.425986   \n",
       "1                         1.096                   0.377815   \n",
       "2                         0.966                   0.895893   \n",
       "3                         0.814                   0.214252   \n",
       "4                         0.994                   0.210580   \n",
       "..                          ...                        ...   \n",
       "722                       1.064                   0.520715   \n",
       "723                       1.488                   0.349651   \n",
       "724                       1.040                   0.498518   \n",
       "725                       1.076                   0.295337   \n",
       "726                       1.280                   0.333407   \n",
       "\n",
       "     t2_opening_kill_rating_mean  t2_opening_kill_rating_std  \\\n",
       "0                          0.934                    0.128468   \n",
       "1                          1.036                    0.157556   \n",
       "2                          0.642                    0.538791   \n",
       "3                          0.940                    0.149131   \n",
       "4                          1.010                    0.154013   \n",
       "..                           ...                         ...   \n",
       "722                        0.968                    0.111427   \n",
       "723                        1.110                    0.123612   \n",
       "724                        0.980                    0.175271   \n",
       "725                        1.016                    0.167404   \n",
       "726                        1.066                    0.095205   \n",
       "\n",
       "     t2_team_win_percent_after_first_kill_mean  \\\n",
       "0                                        50.16   \n",
       "1                                        77.56   \n",
       "2                                        53.14   \n",
       "3                                        64.44   \n",
       "4                                        69.20   \n",
       "..                                         ...   \n",
       "722                                      76.60   \n",
       "723                                      78.58   \n",
       "724                                      81.90   \n",
       "725                                      70.62   \n",
       "726                                      78.98   \n",
       "\n",
       "     t2_team_win_percent_after_first_kill_std  \\\n",
       "0                                   28.897515   \n",
       "1                                    6.753547   \n",
       "2                                   43.875260   \n",
       "3                                    5.683872   \n",
       "4                                    2.916162   \n",
       "..                                        ...   \n",
       "722                                  7.071916   \n",
       "723                                  3.946847   \n",
       "724                                 10.629017   \n",
       "725                                 10.617796   \n",
       "726                                  5.913172   \n",
       "\n",
       "     t2_first_kill_in_won_rounds_mean  t2_first_kill_in_won_rounds_std  \n",
       "0                               14.34                         8.668472  \n",
       "1                               16.14                         5.309840  \n",
       "2                               10.40                         9.329523  \n",
       "3                               13.12                         4.507061  \n",
       "4                               15.02                         6.225560  \n",
       "..                                ...                              ...  \n",
       "722                             13.94                         3.283656  \n",
       "723                             15.04                         4.237263  \n",
       "724                             14.68                         4.787233  \n",
       "725                             12.70                         6.680120  \n",
       "726                             15.24                         4.274857  \n",
       "\n",
       "[727 rows x 100 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totall_df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2477acb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "totall_df_5 = pd.get_dummies(totall_df_4, columns = ['map_id', 'team1_id', 'team2_id'], prefix=['map_id', 'team1_id', 'team2_id']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98677eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>who_win</th>\n",
       "      <th>t1_total_kills_mean</th>\n",
       "      <th>t1_total_kills_std</th>\n",
       "      <th>t1_headshots_mean</th>\n",
       "      <th>t1_headshots_std</th>\n",
       "      <th>t1_total_deaths_mean</th>\n",
       "      <th>t1_total_deaths_std</th>\n",
       "      <th>t1_kd_ratio_mean</th>\n",
       "      <th>t1_kd_ratio_std</th>\n",
       "      <th>t1_damage_per_round_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>team2_id_11135</th>\n",
       "      <th>team2_id_11251</th>\n",
       "      <th>team2_id_11309</th>\n",
       "      <th>team2_id_11312</th>\n",
       "      <th>team2_id_11501</th>\n",
       "      <th>team2_id_11518</th>\n",
       "      <th>team2_id_11585</th>\n",
       "      <th>team2_id_11588</th>\n",
       "      <th>team2_id_11595</th>\n",
       "      <th>team2_id_11654</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>98.4</td>\n",
       "      <td>30.787010</td>\n",
       "      <td>44.96</td>\n",
       "      <td>10.351927</td>\n",
       "      <td>111.4</td>\n",
       "      <td>30.269457</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.094149</td>\n",
       "      <td>71.54</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>139.2</td>\n",
       "      <td>37.252651</td>\n",
       "      <td>41.70</td>\n",
       "      <td>7.852898</td>\n",
       "      <td>138.6</td>\n",
       "      <td>32.450578</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.090686</td>\n",
       "      <td>70.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>160.2</td>\n",
       "      <td>10.998182</td>\n",
       "      <td>49.44</td>\n",
       "      <td>11.350348</td>\n",
       "      <td>125.2</td>\n",
       "      <td>7.249828</td>\n",
       "      <td>1.282</td>\n",
       "      <td>0.092390</td>\n",
       "      <td>76.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>316.2</td>\n",
       "      <td>103.933440</td>\n",
       "      <td>46.80</td>\n",
       "      <td>10.648568</td>\n",
       "      <td>289.0</td>\n",
       "      <td>94.935768</td>\n",
       "      <td>1.156</td>\n",
       "      <td>0.280614</td>\n",
       "      <td>78.66</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>268.6</td>\n",
       "      <td>59.156065</td>\n",
       "      <td>46.94</td>\n",
       "      <td>10.264814</td>\n",
       "      <td>238.2</td>\n",
       "      <td>14.878172</td>\n",
       "      <td>1.130</td>\n",
       "      <td>0.253850</td>\n",
       "      <td>74.70</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>NaN</td>\n",
       "      <td>442.0</td>\n",
       "      <td>83.744851</td>\n",
       "      <td>47.08</td>\n",
       "      <td>9.787012</td>\n",
       "      <td>393.4</td>\n",
       "      <td>25.896718</td>\n",
       "      <td>1.124</td>\n",
       "      <td>0.206359</td>\n",
       "      <td>75.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>NaN</td>\n",
       "      <td>213.6</td>\n",
       "      <td>31.283222</td>\n",
       "      <td>52.44</td>\n",
       "      <td>7.730873</td>\n",
       "      <td>194.4</td>\n",
       "      <td>13.001538</td>\n",
       "      <td>1.102</td>\n",
       "      <td>0.174287</td>\n",
       "      <td>75.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>1.0</td>\n",
       "      <td>86.2</td>\n",
       "      <td>30.353912</td>\n",
       "      <td>43.68</td>\n",
       "      <td>8.210091</td>\n",
       "      <td>92.8</td>\n",
       "      <td>30.694625</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.096623</td>\n",
       "      <td>74.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>0.0</td>\n",
       "      <td>114.6</td>\n",
       "      <td>13.078226</td>\n",
       "      <td>48.76</td>\n",
       "      <td>5.701438</td>\n",
       "      <td>110.6</td>\n",
       "      <td>10.965400</td>\n",
       "      <td>1.042</td>\n",
       "      <td>0.117541</td>\n",
       "      <td>73.74</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>0.0</td>\n",
       "      <td>205.4</td>\n",
       "      <td>42.659583</td>\n",
       "      <td>46.82</td>\n",
       "      <td>8.237330</td>\n",
       "      <td>161.2</td>\n",
       "      <td>29.532355</td>\n",
       "      <td>1.284</td>\n",
       "      <td>0.214812</td>\n",
       "      <td>80.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>727 rows × 933 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     who_win  t1_total_kills_mean  t1_total_kills_std  t1_headshots_mean  \\\n",
       "0        1.0                 98.4           30.787010              44.96   \n",
       "1        1.0                139.2           37.252651              41.70   \n",
       "2        1.0                160.2           10.998182              49.44   \n",
       "3        0.0                316.2          103.933440              46.80   \n",
       "4        1.0                268.6           59.156065              46.94   \n",
       "..       ...                  ...                 ...                ...   \n",
       "722      NaN                442.0           83.744851              47.08   \n",
       "723      NaN                213.6           31.283222              52.44   \n",
       "724      1.0                 86.2           30.353912              43.68   \n",
       "725      0.0                114.6           13.078226              48.76   \n",
       "726      0.0                205.4           42.659583              46.82   \n",
       "\n",
       "     t1_headshots_std  t1_total_deaths_mean  t1_total_deaths_std  \\\n",
       "0           10.351927                 111.4            30.269457   \n",
       "1            7.852898                 138.6            32.450578   \n",
       "2           11.350348                 125.2             7.249828   \n",
       "3           10.648568                 289.0            94.935768   \n",
       "4           10.264814                 238.2            14.878172   \n",
       "..                ...                   ...                  ...   \n",
       "722          9.787012                 393.4            25.896718   \n",
       "723          7.730873                 194.4            13.001538   \n",
       "724          8.210091                  92.8            30.694625   \n",
       "725          5.701438                 110.6            10.965400   \n",
       "726          8.237330                 161.2            29.532355   \n",
       "\n",
       "     t1_kd_ratio_mean  t1_kd_ratio_std  t1_damage_per_round_mean  ...  \\\n",
       "0               0.876         0.094149                     71.54  ...   \n",
       "1               0.996         0.090686                     70.62  ...   \n",
       "2               1.282         0.092390                     76.76  ...   \n",
       "3               1.156         0.280614                     78.66  ...   \n",
       "4               1.130         0.253850                     74.70  ...   \n",
       "..                ...              ...                       ...  ...   \n",
       "722             1.124         0.206359                     75.20  ...   \n",
       "723             1.102         0.174287                     75.80  ...   \n",
       "724             0.928         0.096623                     74.04  ...   \n",
       "725             1.042         0.117541                     73.74  ...   \n",
       "726             1.284         0.214812                     80.28  ...   \n",
       "\n",
       "     team2_id_11135  team2_id_11251  team2_id_11309  team2_id_11312  \\\n",
       "0                 0               0               0               0   \n",
       "1                 0               0               0               0   \n",
       "2                 0               0               0               0   \n",
       "3                 0               0               0               0   \n",
       "4                 0               0               0               0   \n",
       "..              ...             ...             ...             ...   \n",
       "722               0               0               0               0   \n",
       "723               0               0               0               0   \n",
       "724               0               0               0               0   \n",
       "725               0               0               0               0   \n",
       "726               0               0               0               0   \n",
       "\n",
       "     team2_id_11501  team2_id_11518  team2_id_11585  team2_id_11588  \\\n",
       "0                 0               0               0               0   \n",
       "1                 0               0               0               0   \n",
       "2                 0               0               0               0   \n",
       "3                 0               0               0               0   \n",
       "4                 0               0               0               0   \n",
       "..              ...             ...             ...             ...   \n",
       "722               0               0               0               0   \n",
       "723               0               0               0               0   \n",
       "724               0               0               0               0   \n",
       "725               0               0               0               0   \n",
       "726               0               0               0               0   \n",
       "\n",
       "     team2_id_11595  team2_id_11654  \n",
       "0                 0               0  \n",
       "1                 0               0  \n",
       "2                 0               0  \n",
       "3                 0               0  \n",
       "4                 0               0  \n",
       "..              ...             ...  \n",
       "722               0               0  \n",
       "723               0               0  \n",
       "724               0               0  \n",
       "725               0               0  \n",
       "726               0               0  \n",
       "\n",
       "[727 rows x 933 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totall_df_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3139940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_train = totall_df_5[totall_df_5.who_win.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a75e6810",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_res = totall_df_5[totall_df_5.who_win.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79b988a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_res = Data_res.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5c6bb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1_total_kills_mean</th>\n",
       "      <th>t1_total_kills_std</th>\n",
       "      <th>t1_headshots_mean</th>\n",
       "      <th>t1_headshots_std</th>\n",
       "      <th>t1_total_deaths_mean</th>\n",
       "      <th>t1_total_deaths_std</th>\n",
       "      <th>t1_kd_ratio_mean</th>\n",
       "      <th>t1_kd_ratio_std</th>\n",
       "      <th>t1_damage_per_round_mean</th>\n",
       "      <th>t1_damage_per_round_std</th>\n",
       "      <th>...</th>\n",
       "      <th>team2_id_11135</th>\n",
       "      <th>team2_id_11251</th>\n",
       "      <th>team2_id_11309</th>\n",
       "      <th>team2_id_11312</th>\n",
       "      <th>team2_id_11501</th>\n",
       "      <th>team2_id_11518</th>\n",
       "      <th>team2_id_11585</th>\n",
       "      <th>team2_id_11588</th>\n",
       "      <th>team2_id_11595</th>\n",
       "      <th>team2_id_11654</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>145.2</td>\n",
       "      <td>58.758489</td>\n",
       "      <td>41.54</td>\n",
       "      <td>11.878148</td>\n",
       "      <td>124.4</td>\n",
       "      <td>44.156993</td>\n",
       "      <td>1.160</td>\n",
       "      <td>0.124097</td>\n",
       "      <td>78.08</td>\n",
       "      <td>5.437426</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>249.4</td>\n",
       "      <td>68.610786</td>\n",
       "      <td>42.70</td>\n",
       "      <td>8.123054</td>\n",
       "      <td>223.4</td>\n",
       "      <td>42.683018</td>\n",
       "      <td>1.100</td>\n",
       "      <td>0.167809</td>\n",
       "      <td>78.36</td>\n",
       "      <td>7.285492</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>272.2</td>\n",
       "      <td>31.587339</td>\n",
       "      <td>42.66</td>\n",
       "      <td>7.838010</td>\n",
       "      <td>285.4</td>\n",
       "      <td>25.120510</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.155126</td>\n",
       "      <td>71.58</td>\n",
       "      <td>8.906941</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>285.8</td>\n",
       "      <td>21.027601</td>\n",
       "      <td>40.86</td>\n",
       "      <td>9.816843</td>\n",
       "      <td>283.6</td>\n",
       "      <td>19.815146</td>\n",
       "      <td>1.010</td>\n",
       "      <td>0.079498</td>\n",
       "      <td>71.74</td>\n",
       "      <td>5.770130</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>128.6</td>\n",
       "      <td>9.264988</td>\n",
       "      <td>45.24</td>\n",
       "      <td>10.479427</td>\n",
       "      <td>117.2</td>\n",
       "      <td>11.805084</td>\n",
       "      <td>1.106</td>\n",
       "      <td>0.123548</td>\n",
       "      <td>75.92</td>\n",
       "      <td>6.994398</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>261.2</td>\n",
       "      <td>62.792993</td>\n",
       "      <td>37.14</td>\n",
       "      <td>6.985871</td>\n",
       "      <td>241.4</td>\n",
       "      <td>54.529258</td>\n",
       "      <td>1.082</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>73.54</td>\n",
       "      <td>4.910234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>313.2</td>\n",
       "      <td>18.225257</td>\n",
       "      <td>43.36</td>\n",
       "      <td>8.201122</td>\n",
       "      <td>319.6</td>\n",
       "      <td>48.812294</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.133716</td>\n",
       "      <td>68.72</td>\n",
       "      <td>2.172004</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>300.4</td>\n",
       "      <td>47.407172</td>\n",
       "      <td>48.44</td>\n",
       "      <td>8.588737</td>\n",
       "      <td>292.8</td>\n",
       "      <td>40.434639</td>\n",
       "      <td>1.036</td>\n",
       "      <td>0.152132</td>\n",
       "      <td>72.78</td>\n",
       "      <td>4.990551</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>247.8</td>\n",
       "      <td>38.690567</td>\n",
       "      <td>50.78</td>\n",
       "      <td>7.039432</td>\n",
       "      <td>218.4</td>\n",
       "      <td>19.064102</td>\n",
       "      <td>1.132</td>\n",
       "      <td>0.120897</td>\n",
       "      <td>74.10</td>\n",
       "      <td>7.424823</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>397.2</td>\n",
       "      <td>79.393703</td>\n",
       "      <td>47.32</td>\n",
       "      <td>10.005678</td>\n",
       "      <td>350.2</td>\n",
       "      <td>24.514486</td>\n",
       "      <td>1.132</td>\n",
       "      <td>0.216832</td>\n",
       "      <td>75.12</td>\n",
       "      <td>10.017864</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>156.6</td>\n",
       "      <td>24.483464</td>\n",
       "      <td>47.56</td>\n",
       "      <td>9.614697</td>\n",
       "      <td>128.0</td>\n",
       "      <td>27.261695</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0.220273</td>\n",
       "      <td>78.62</td>\n",
       "      <td>6.044965</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>370.4</td>\n",
       "      <td>76.017366</td>\n",
       "      <td>41.96</td>\n",
       "      <td>9.193171</td>\n",
       "      <td>369.0</td>\n",
       "      <td>67.696381</td>\n",
       "      <td>1.022</td>\n",
       "      <td>0.197525</td>\n",
       "      <td>72.16</td>\n",
       "      <td>10.948169</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>143.8</td>\n",
       "      <td>40.454419</td>\n",
       "      <td>41.20</td>\n",
       "      <td>10.507521</td>\n",
       "      <td>149.0</td>\n",
       "      <td>35.524639</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.100916</td>\n",
       "      <td>70.12</td>\n",
       "      <td>8.513613</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>266.4</td>\n",
       "      <td>80.599256</td>\n",
       "      <td>40.58</td>\n",
       "      <td>7.927269</td>\n",
       "      <td>255.6</td>\n",
       "      <td>77.507677</td>\n",
       "      <td>1.050</td>\n",
       "      <td>0.067231</td>\n",
       "      <td>77.92</td>\n",
       "      <td>7.668742</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>230.6</td>\n",
       "      <td>20.606795</td>\n",
       "      <td>45.78</td>\n",
       "      <td>8.028549</td>\n",
       "      <td>205.4</td>\n",
       "      <td>8.260751</td>\n",
       "      <td>1.128</td>\n",
       "      <td>0.121885</td>\n",
       "      <td>77.88</td>\n",
       "      <td>8.221046</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>312.2</td>\n",
       "      <td>41.431389</td>\n",
       "      <td>47.90</td>\n",
       "      <td>8.386418</td>\n",
       "      <td>299.0</td>\n",
       "      <td>37.868192</td>\n",
       "      <td>1.056</td>\n",
       "      <td>0.160823</td>\n",
       "      <td>73.16</td>\n",
       "      <td>5.079213</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>379.0</td>\n",
       "      <td>28.368997</td>\n",
       "      <td>45.28</td>\n",
       "      <td>8.037263</td>\n",
       "      <td>364.0</td>\n",
       "      <td>50.687277</td>\n",
       "      <td>1.058</td>\n",
       "      <td>0.148243</td>\n",
       "      <td>73.48</td>\n",
       "      <td>4.635256</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>272.2</td>\n",
       "      <td>81.100925</td>\n",
       "      <td>41.02</td>\n",
       "      <td>8.820748</td>\n",
       "      <td>235.4</td>\n",
       "      <td>75.706275</td>\n",
       "      <td>1.180</td>\n",
       "      <td>0.246901</td>\n",
       "      <td>75.94</td>\n",
       "      <td>5.341386</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>225.8</td>\n",
       "      <td>19.093454</td>\n",
       "      <td>43.66</td>\n",
       "      <td>10.236132</td>\n",
       "      <td>226.4</td>\n",
       "      <td>18.488916</td>\n",
       "      <td>1.002</td>\n",
       "      <td>0.113737</td>\n",
       "      <td>71.78</td>\n",
       "      <td>7.189826</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>286.8</td>\n",
       "      <td>30.314353</td>\n",
       "      <td>46.24</td>\n",
       "      <td>8.146803</td>\n",
       "      <td>285.0</td>\n",
       "      <td>14.764823</td>\n",
       "      <td>1.008</td>\n",
       "      <td>0.130292</td>\n",
       "      <td>69.96</td>\n",
       "      <td>5.470868</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>254.0</td>\n",
       "      <td>23.486166</td>\n",
       "      <td>43.10</td>\n",
       "      <td>9.408719</td>\n",
       "      <td>253.2</td>\n",
       "      <td>27.374441</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.172673</td>\n",
       "      <td>72.42</td>\n",
       "      <td>3.591880</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>196.4</td>\n",
       "      <td>28.765257</td>\n",
       "      <td>52.76</td>\n",
       "      <td>7.156144</td>\n",
       "      <td>183.0</td>\n",
       "      <td>12.853015</td>\n",
       "      <td>1.076</td>\n",
       "      <td>0.159324</td>\n",
       "      <td>75.86</td>\n",
       "      <td>9.208605</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>415.6</td>\n",
       "      <td>82.453866</td>\n",
       "      <td>47.32</td>\n",
       "      <td>10.098594</td>\n",
       "      <td>367.4</td>\n",
       "      <td>25.996923</td>\n",
       "      <td>1.134</td>\n",
       "      <td>0.223482</td>\n",
       "      <td>75.02</td>\n",
       "      <td>9.505872</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>196.4</td>\n",
       "      <td>15.344054</td>\n",
       "      <td>46.72</td>\n",
       "      <td>10.144437</td>\n",
       "      <td>168.6</td>\n",
       "      <td>17.828068</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.105186</td>\n",
       "      <td>76.72</td>\n",
       "      <td>3.919898</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>264.8</td>\n",
       "      <td>23.574563</td>\n",
       "      <td>48.86</td>\n",
       "      <td>7.658355</td>\n",
       "      <td>215.8</td>\n",
       "      <td>25.158696</td>\n",
       "      <td>1.246</td>\n",
       "      <td>0.186290</td>\n",
       "      <td>78.60</td>\n",
       "      <td>6.451356</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>263.4</td>\n",
       "      <td>41.359884</td>\n",
       "      <td>50.46</td>\n",
       "      <td>6.627096</td>\n",
       "      <td>237.2</td>\n",
       "      <td>19.630588</td>\n",
       "      <td>1.106</td>\n",
       "      <td>0.127530</td>\n",
       "      <td>73.64</td>\n",
       "      <td>8.011392</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>174.6</td>\n",
       "      <td>26.119724</td>\n",
       "      <td>47.92</td>\n",
       "      <td>9.036238</td>\n",
       "      <td>141.6</td>\n",
       "      <td>28.047103</td>\n",
       "      <td>1.256</td>\n",
       "      <td>0.215926</td>\n",
       "      <td>78.04</td>\n",
       "      <td>6.080987</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>174.4</td>\n",
       "      <td>24.952755</td>\n",
       "      <td>45.96</td>\n",
       "      <td>9.633400</td>\n",
       "      <td>148.0</td>\n",
       "      <td>45.598246</td>\n",
       "      <td>1.232</td>\n",
       "      <td>0.203706</td>\n",
       "      <td>79.32</td>\n",
       "      <td>6.869178</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>442.0</td>\n",
       "      <td>83.744851</td>\n",
       "      <td>47.08</td>\n",
       "      <td>9.787012</td>\n",
       "      <td>393.4</td>\n",
       "      <td>25.896718</td>\n",
       "      <td>1.124</td>\n",
       "      <td>0.206359</td>\n",
       "      <td>75.20</td>\n",
       "      <td>9.615612</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>213.6</td>\n",
       "      <td>31.283222</td>\n",
       "      <td>52.44</td>\n",
       "      <td>7.730873</td>\n",
       "      <td>194.4</td>\n",
       "      <td>13.001538</td>\n",
       "      <td>1.102</td>\n",
       "      <td>0.174287</td>\n",
       "      <td>75.80</td>\n",
       "      <td>8.489759</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 932 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     t1_total_kills_mean  t1_total_kills_std  t1_headshots_mean  \\\n",
       "694                145.2           58.758489              41.54   \n",
       "695                249.4           68.610786              42.70   \n",
       "696                272.2           31.587339              42.66   \n",
       "697                285.8           21.027601              40.86   \n",
       "698                128.6            9.264988              45.24   \n",
       "699                261.2           62.792993              37.14   \n",
       "700                313.2           18.225257              43.36   \n",
       "701                300.4           47.407172              48.44   \n",
       "702                247.8           38.690567              50.78   \n",
       "703                397.2           79.393703              47.32   \n",
       "704                156.6           24.483464              47.56   \n",
       "705                370.4           76.017366              41.96   \n",
       "706                143.8           40.454419              41.20   \n",
       "707                266.4           80.599256              40.58   \n",
       "708                230.6           20.606795              45.78   \n",
       "709                312.2           41.431389              47.90   \n",
       "710                379.0           28.368997              45.28   \n",
       "711                272.2           81.100925              41.02   \n",
       "712                225.8           19.093454              43.66   \n",
       "713                286.8           30.314353              46.24   \n",
       "714                254.0           23.486166              43.10   \n",
       "715                196.4           28.765257              52.76   \n",
       "716                415.6           82.453866              47.32   \n",
       "717                196.4           15.344054              46.72   \n",
       "718                264.8           23.574563              48.86   \n",
       "719                263.4           41.359884              50.46   \n",
       "720                174.6           26.119724              47.92   \n",
       "721                174.4           24.952755              45.96   \n",
       "722                442.0           83.744851              47.08   \n",
       "723                213.6           31.283222              52.44   \n",
       "\n",
       "     t1_headshots_std  t1_total_deaths_mean  t1_total_deaths_std  \\\n",
       "694         11.878148                 124.4            44.156993   \n",
       "695          8.123054                 223.4            42.683018   \n",
       "696          7.838010                 285.4            25.120510   \n",
       "697          9.816843                 283.6            19.815146   \n",
       "698         10.479427                 117.2            11.805084   \n",
       "699          6.985871                 241.4            54.529258   \n",
       "700          8.201122                 319.6            48.812294   \n",
       "701          8.588737                 292.8            40.434639   \n",
       "702          7.039432                 218.4            19.064102   \n",
       "703         10.005678                 350.2            24.514486   \n",
       "704          9.614697                 128.0            27.261695   \n",
       "705          9.193171                 369.0            67.696381   \n",
       "706         10.507521                 149.0            35.524639   \n",
       "707          7.927269                 255.6            77.507677   \n",
       "708          8.028549                 205.4             8.260751   \n",
       "709          8.386418                 299.0            37.868192   \n",
       "710          8.037263                 364.0            50.687277   \n",
       "711          8.820748                 235.4            75.706275   \n",
       "712         10.236132                 226.4            18.488916   \n",
       "713          8.146803                 285.0            14.764823   \n",
       "714          9.408719                 253.2            27.374441   \n",
       "715          7.156144                 183.0            12.853015   \n",
       "716         10.098594                 367.4            25.996923   \n",
       "717         10.144437                 168.6            17.828068   \n",
       "718          7.658355                 215.8            25.158696   \n",
       "719          6.627096                 237.2            19.630588   \n",
       "720          9.036238                 141.6            28.047103   \n",
       "721          9.633400                 148.0            45.598246   \n",
       "722          9.787012                 393.4            25.896718   \n",
       "723          7.730873                 194.4            13.001538   \n",
       "\n",
       "     t1_kd_ratio_mean  t1_kd_ratio_std  t1_damage_per_round_mean  \\\n",
       "694             1.160         0.124097                     78.08   \n",
       "695             1.100         0.167809                     78.36   \n",
       "696             0.964         0.155126                     71.58   \n",
       "697             1.010         0.079498                     71.74   \n",
       "698             1.106         0.123548                     75.92   \n",
       "699             1.082         0.108333                     73.54   \n",
       "700             1.000         0.133716                     68.72   \n",
       "701             1.036         0.152132                     72.78   \n",
       "702             1.132         0.120897                     74.10   \n",
       "703             1.132         0.216832                     75.12   \n",
       "704             1.250         0.220273                     78.62   \n",
       "705             1.022         0.197525                     72.16   \n",
       "706             0.954         0.100916                     70.12   \n",
       "707             1.050         0.067231                     77.92   \n",
       "708             1.128         0.121885                     77.88   \n",
       "709             1.056         0.160823                     73.16   \n",
       "710             1.058         0.148243                     73.48   \n",
       "711             1.180         0.246901                     75.94   \n",
       "712             1.002         0.113737                     71.78   \n",
       "713             1.008         0.130292                     69.96   \n",
       "714             1.018         0.172673                     72.42   \n",
       "715             1.076         0.159324                     75.86   \n",
       "716             1.134         0.223482                     75.02   \n",
       "717             1.176         0.105186                     76.72   \n",
       "718             1.246         0.186290                     78.60   \n",
       "719             1.106         0.127530                     73.64   \n",
       "720             1.256         0.215926                     78.04   \n",
       "721             1.232         0.203706                     79.32   \n",
       "722             1.124         0.206359                     75.20   \n",
       "723             1.102         0.174287                     75.80   \n",
       "\n",
       "     t1_damage_per_round_std  ...  team2_id_11135  team2_id_11251  \\\n",
       "694                 5.437426  ...               0               0   \n",
       "695                 7.285492  ...               0               0   \n",
       "696                 8.906941  ...               0               0   \n",
       "697                 5.770130  ...               0               0   \n",
       "698                 6.994398  ...               0               0   \n",
       "699                 4.910234  ...               0               0   \n",
       "700                 2.172004  ...               0               0   \n",
       "701                 4.990551  ...               0               0   \n",
       "702                 7.424823  ...               0               0   \n",
       "703                10.017864  ...               0               0   \n",
       "704                 6.044965  ...               0               0   \n",
       "705                10.948169  ...               0               0   \n",
       "706                 8.513613  ...               0               0   \n",
       "707                 7.668742  ...               0               0   \n",
       "708                 8.221046  ...               0               0   \n",
       "709                 5.079213  ...               0               0   \n",
       "710                 4.635256  ...               0               0   \n",
       "711                 5.341386  ...               0               0   \n",
       "712                 7.189826  ...               0               0   \n",
       "713                 5.470868  ...               0               0   \n",
       "714                 3.591880  ...               0               0   \n",
       "715                 9.208605  ...               0               0   \n",
       "716                 9.505872  ...               0               0   \n",
       "717                 3.919898  ...               0               0   \n",
       "718                 6.451356  ...               0               0   \n",
       "719                 8.011392  ...               0               0   \n",
       "720                 6.080987  ...               0               0   \n",
       "721                 6.869178  ...               0               0   \n",
       "722                 9.615612  ...               0               0   \n",
       "723                 8.489759  ...               0               0   \n",
       "\n",
       "     team2_id_11309  team2_id_11312  team2_id_11501  team2_id_11518  \\\n",
       "694               0               0               0               0   \n",
       "695               0               0               0               0   \n",
       "696               0               0               0               0   \n",
       "697               0               0               0               0   \n",
       "698               0               0               0               0   \n",
       "699               0               0               0               0   \n",
       "700               0               0               0               0   \n",
       "701               0               0               0               0   \n",
       "702               0               0               0               0   \n",
       "703               0               0               0               0   \n",
       "704               0               0               0               0   \n",
       "705               0               0               0               0   \n",
       "706               0               0               0               0   \n",
       "707               0               0               0               0   \n",
       "708               0               0               0               0   \n",
       "709               0               0               0               0   \n",
       "710               0               0               0               0   \n",
       "711               0               0               0               0   \n",
       "712               0               0               0               0   \n",
       "713               0               0               0               0   \n",
       "714               0               0               0               0   \n",
       "715               0               0               0               0   \n",
       "716               0               0               0               0   \n",
       "717               0               0               0               0   \n",
       "718               0               0               0               0   \n",
       "719               0               0               0               0   \n",
       "720               0               0               0               0   \n",
       "721               0               0               0               0   \n",
       "722               0               0               0               0   \n",
       "723               0               0               0               0   \n",
       "\n",
       "     team2_id_11585  team2_id_11588  team2_id_11595  team2_id_11654  \n",
       "694               0               0               0               0  \n",
       "695               0               0               0               0  \n",
       "696               0               0               0               0  \n",
       "697               0               0               0               0  \n",
       "698               0               0               0               0  \n",
       "699               0               0               0               0  \n",
       "700               0               0               0               0  \n",
       "701               0               0               0               0  \n",
       "702               0               0               0               0  \n",
       "703               0               0               0               0  \n",
       "704               0               0               0               0  \n",
       "705               0               0               0               0  \n",
       "706               0               0               0               0  \n",
       "707               0               0               0               0  \n",
       "708               0               0               0               0  \n",
       "709               0               0               0               0  \n",
       "710               0               0               0               0  \n",
       "711               0               0               0               0  \n",
       "712               0               0               0               0  \n",
       "713               0               0               0               0  \n",
       "714               0               0               0               0  \n",
       "715               0               0               0               0  \n",
       "716               0               0               0               0  \n",
       "717               0               0               0               0  \n",
       "718               0               0               0               0  \n",
       "719               0               0               0               0  \n",
       "720               0               0               0               0  \n",
       "721               0               0               0               0  \n",
       "722               0               0               0               0  \n",
       "723               0               0               0               0  \n",
       "\n",
       "[30 rows x 932 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45045911",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Data_train.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78acb676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1_total_kills_mean</th>\n",
       "      <th>t1_total_kills_std</th>\n",
       "      <th>t1_headshots_mean</th>\n",
       "      <th>t1_headshots_std</th>\n",
       "      <th>t1_total_deaths_mean</th>\n",
       "      <th>t1_total_deaths_std</th>\n",
       "      <th>t1_kd_ratio_mean</th>\n",
       "      <th>t1_kd_ratio_std</th>\n",
       "      <th>t1_damage_per_round_mean</th>\n",
       "      <th>t1_damage_per_round_std</th>\n",
       "      <th>...</th>\n",
       "      <th>team2_id_11135</th>\n",
       "      <th>team2_id_11251</th>\n",
       "      <th>team2_id_11309</th>\n",
       "      <th>team2_id_11312</th>\n",
       "      <th>team2_id_11501</th>\n",
       "      <th>team2_id_11518</th>\n",
       "      <th>team2_id_11585</th>\n",
       "      <th>team2_id_11588</th>\n",
       "      <th>team2_id_11595</th>\n",
       "      <th>team2_id_11654</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98.4</td>\n",
       "      <td>30.787010</td>\n",
       "      <td>44.96</td>\n",
       "      <td>10.351927</td>\n",
       "      <td>111.4</td>\n",
       "      <td>30.269457</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.094149</td>\n",
       "      <td>71.54</td>\n",
       "      <td>10.405114</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139.2</td>\n",
       "      <td>37.252651</td>\n",
       "      <td>41.70</td>\n",
       "      <td>7.852898</td>\n",
       "      <td>138.6</td>\n",
       "      <td>32.450578</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.090686</td>\n",
       "      <td>70.62</td>\n",
       "      <td>8.839321</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>160.2</td>\n",
       "      <td>10.998182</td>\n",
       "      <td>49.44</td>\n",
       "      <td>11.350348</td>\n",
       "      <td>125.2</td>\n",
       "      <td>7.249828</td>\n",
       "      <td>1.282</td>\n",
       "      <td>0.092390</td>\n",
       "      <td>76.76</td>\n",
       "      <td>4.459865</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316.2</td>\n",
       "      <td>103.933440</td>\n",
       "      <td>46.80</td>\n",
       "      <td>10.648568</td>\n",
       "      <td>289.0</td>\n",
       "      <td>94.935768</td>\n",
       "      <td>1.156</td>\n",
       "      <td>0.280614</td>\n",
       "      <td>78.66</td>\n",
       "      <td>10.803074</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>268.6</td>\n",
       "      <td>59.156065</td>\n",
       "      <td>46.94</td>\n",
       "      <td>10.264814</td>\n",
       "      <td>238.2</td>\n",
       "      <td>14.878172</td>\n",
       "      <td>1.130</td>\n",
       "      <td>0.253850</td>\n",
       "      <td>74.70</td>\n",
       "      <td>11.286275</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>203.4</td>\n",
       "      <td>31.270433</td>\n",
       "      <td>42.82</td>\n",
       "      <td>6.976933</td>\n",
       "      <td>204.4</td>\n",
       "      <td>13.836184</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.107592</td>\n",
       "      <td>74.86</td>\n",
       "      <td>7.487216</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>205.8</td>\n",
       "      <td>28.812497</td>\n",
       "      <td>46.18</td>\n",
       "      <td>10.662157</td>\n",
       "      <td>207.0</td>\n",
       "      <td>23.383755</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.067705</td>\n",
       "      <td>71.26</td>\n",
       "      <td>7.727768</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>86.2</td>\n",
       "      <td>30.353912</td>\n",
       "      <td>43.68</td>\n",
       "      <td>8.210091</td>\n",
       "      <td>92.8</td>\n",
       "      <td>30.694625</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.096623</td>\n",
       "      <td>74.04</td>\n",
       "      <td>10.292832</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>114.6</td>\n",
       "      <td>13.078226</td>\n",
       "      <td>48.76</td>\n",
       "      <td>5.701438</td>\n",
       "      <td>110.6</td>\n",
       "      <td>10.965400</td>\n",
       "      <td>1.042</td>\n",
       "      <td>0.117541</td>\n",
       "      <td>73.74</td>\n",
       "      <td>9.493493</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>205.4</td>\n",
       "      <td>42.659583</td>\n",
       "      <td>46.82</td>\n",
       "      <td>8.237330</td>\n",
       "      <td>161.2</td>\n",
       "      <td>29.532355</td>\n",
       "      <td>1.284</td>\n",
       "      <td>0.214812</td>\n",
       "      <td>80.28</td>\n",
       "      <td>7.826468</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>697 rows × 932 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     t1_total_kills_mean  t1_total_kills_std  t1_headshots_mean  \\\n",
       "0                   98.4           30.787010              44.96   \n",
       "1                  139.2           37.252651              41.70   \n",
       "2                  160.2           10.998182              49.44   \n",
       "3                  316.2          103.933440              46.80   \n",
       "4                  268.6           59.156065              46.94   \n",
       "..                   ...                 ...                ...   \n",
       "692                203.4           31.270433              42.82   \n",
       "693                205.8           28.812497              46.18   \n",
       "724                 86.2           30.353912              43.68   \n",
       "725                114.6           13.078226              48.76   \n",
       "726                205.4           42.659583              46.82   \n",
       "\n",
       "     t1_headshots_std  t1_total_deaths_mean  t1_total_deaths_std  \\\n",
       "0           10.351927                 111.4            30.269457   \n",
       "1            7.852898                 138.6            32.450578   \n",
       "2           11.350348                 125.2             7.249828   \n",
       "3           10.648568                 289.0            94.935768   \n",
       "4           10.264814                 238.2            14.878172   \n",
       "..                ...                   ...                  ...   \n",
       "692          6.976933                 204.4            13.836184   \n",
       "693         10.662157                 207.0            23.383755   \n",
       "724          8.210091                  92.8            30.694625   \n",
       "725          5.701438                 110.6            10.965400   \n",
       "726          8.237330                 161.2            29.532355   \n",
       "\n",
       "     t1_kd_ratio_mean  t1_kd_ratio_std  t1_damage_per_round_mean  \\\n",
       "0               0.876         0.094149                     71.54   \n",
       "1               0.996         0.090686                     70.62   \n",
       "2               1.282         0.092390                     76.76   \n",
       "3               1.156         0.280614                     78.66   \n",
       "4               1.130         0.253850                     74.70   \n",
       "..                ...              ...                       ...   \n",
       "692             0.992         0.107592                     74.86   \n",
       "693             0.994         0.067705                     71.26   \n",
       "724             0.928         0.096623                     74.04   \n",
       "725             1.042         0.117541                     73.74   \n",
       "726             1.284         0.214812                     80.28   \n",
       "\n",
       "     t1_damage_per_round_std  ...  team2_id_11135  team2_id_11251  \\\n",
       "0                  10.405114  ...               0               0   \n",
       "1                   8.839321  ...               0               0   \n",
       "2                   4.459865  ...               0               0   \n",
       "3                  10.803074  ...               0               0   \n",
       "4                  11.286275  ...               0               0   \n",
       "..                       ...  ...             ...             ...   \n",
       "692                 7.487216  ...               0               0   \n",
       "693                 7.727768  ...               0               0   \n",
       "724                10.292832  ...               0               0   \n",
       "725                 9.493493  ...               0               0   \n",
       "726                 7.826468  ...               0               0   \n",
       "\n",
       "     team2_id_11309  team2_id_11312  team2_id_11501  team2_id_11518  \\\n",
       "0                 0               0               0               0   \n",
       "1                 0               0               0               0   \n",
       "2                 0               0               0               0   \n",
       "3                 0               0               0               0   \n",
       "4                 0               0               0               0   \n",
       "..              ...             ...             ...             ...   \n",
       "692               0               0               0               0   \n",
       "693               0               0               0               0   \n",
       "724               0               0               0               0   \n",
       "725               0               0               0               0   \n",
       "726               0               0               0               0   \n",
       "\n",
       "     team2_id_11585  team2_id_11588  team2_id_11595  team2_id_11654  \n",
       "0                 0               0               0               0  \n",
       "1                 0               0               0               0  \n",
       "2                 0               0               0               0  \n",
       "3                 0               0               0               0  \n",
       "4                 0               0               0               0  \n",
       "..              ...             ...             ...             ...  \n",
       "692               0               0               0               0  \n",
       "693               0               0               0               0  \n",
       "724               0               0               0               0  \n",
       "725               0               0               0               0  \n",
       "726               0               0               0               0  \n",
       "\n",
       "[697 rows x 932 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d301598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Data_train['who_win'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c4daf508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['t1_total_kills_mean', 't1_total_kills_std', 't1_headshots_mean',\n",
       "       't1_headshots_std', 't1_total_deaths_mean', 't1_total_deaths_std',\n",
       "       't1_kd_ratio_mean', 't1_kd_ratio_std', 't1_damage_per_round_mean',\n",
       "       't1_damage_per_round_std',\n",
       "       ...\n",
       "       'team2_id_11135', 'team2_id_11251', 'team2_id_11309', 'team2_id_11312',\n",
       "       'team2_id_11501', 'team2_id_11518', 'team2_id_11585', 'team2_id_11588',\n",
       "       'team2_id_11595', 'team2_id_11654'],\n",
       "      dtype='object', length=932)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8c8c3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t1_total_kills_mean',\n",
       " 't1_total_kills_std',\n",
       " 't1_headshots_mean',\n",
       " 't1_headshots_std',\n",
       " 't1_total_deaths_mean',\n",
       " 't1_total_deaths_std',\n",
       " 't1_kd_ratio_mean',\n",
       " 't1_kd_ratio_std',\n",
       " 't1_damage_per_round_mean',\n",
       " 't1_damage_per_round_std',\n",
       " 't1_grenade_damage_per_round_mean',\n",
       " 't1_grenade_damage_per_round_std',\n",
       " 't1_maps_played_mean',\n",
       " 't1_maps_played_std',\n",
       " 't1_rounds_played_mean',\n",
       " 't1_rounds_played_std',\n",
       " 't1_kills_per_round_mean',\n",
       " 't1_kills_per_round_std',\n",
       " 't1_assists_per_round_mean',\n",
       " 't1_assists_per_round_std',\n",
       " 't1_deaths_per_round_mean',\n",
       " 't1_deaths_per_round_std',\n",
       " 't1_saved_by_teammate_per_round_mean',\n",
       " 't1_saved_by_teammate_per_round_std',\n",
       " 't1_saved_teammates_per_round_mean',\n",
       " 't1_saved_teammates_per_round_std',\n",
       " 't1_rating_mean',\n",
       " 't1_rating_std',\n",
       " 't1_kill_death_mean',\n",
       " 't1_kill_death_std',\n",
       " 't1_kill_round_mean',\n",
       " 't1_kill_round_std',\n",
       " 't1_rounds_with_kills_mean',\n",
       " 't1_rounds_with_kills_std',\n",
       " 't1_kill_death_difference_mean',\n",
       " 't1_kill_death_difference_std',\n",
       " 't1_total_opening_kills_mean',\n",
       " 't1_total_opening_kills_std',\n",
       " 't1_total_opening_deaths_mean',\n",
       " 't1_total_opening_deaths_std',\n",
       " 't1_opening_kill_ratio_mean',\n",
       " 't1_opening_kill_ratio_std',\n",
       " 't1_opening_kill_rating_mean',\n",
       " 't1_opening_kill_rating_std',\n",
       " 't1_team_win_percent_after_first_kill_mean',\n",
       " 't1_team_win_percent_after_first_kill_std',\n",
       " 't1_first_kill_in_won_rounds_mean',\n",
       " 't1_first_kill_in_won_rounds_std',\n",
       " 't2_total_kills_mean',\n",
       " 't2_total_kills_std',\n",
       " 't2_headshots_mean',\n",
       " 't2_headshots_std',\n",
       " 't2_total_deaths_mean',\n",
       " 't2_total_deaths_std',\n",
       " 't2_kd_ratio_mean',\n",
       " 't2_kd_ratio_std',\n",
       " 't2_damage_per_round_mean',\n",
       " 't2_damage_per_round_std',\n",
       " 't2_grenade_damage_per_round_mean',\n",
       " 't2_grenade_damage_per_round_std',\n",
       " 't2_maps_played_mean',\n",
       " 't2_maps_played_std',\n",
       " 't2_rounds_played_mean',\n",
       " 't2_rounds_played_std',\n",
       " 't2_kills_per_round_mean',\n",
       " 't2_kills_per_round_std',\n",
       " 't2_assists_per_round_mean',\n",
       " 't2_assists_per_round_std',\n",
       " 't2_deaths_per_round_mean',\n",
       " 't2_deaths_per_round_std',\n",
       " 't2_saved_by_teammate_per_round_mean',\n",
       " 't2_saved_by_teammate_per_round_std',\n",
       " 't2_saved_teammates_per_round_mean',\n",
       " 't2_saved_teammates_per_round_std',\n",
       " 't2_rating_mean',\n",
       " 't2_rating_std',\n",
       " 't2_kill_death_mean',\n",
       " 't2_kill_death_std',\n",
       " 't2_kill_round_mean',\n",
       " 't2_kill_round_std',\n",
       " 't2_rounds_with_kills_mean',\n",
       " 't2_rounds_with_kills_std',\n",
       " 't2_kill_death_difference_mean',\n",
       " 't2_kill_death_difference_std',\n",
       " 't2_total_opening_kills_mean',\n",
       " 't2_total_opening_kills_std',\n",
       " 't2_total_opening_deaths_mean',\n",
       " 't2_total_opening_deaths_std',\n",
       " 't2_opening_kill_ratio_mean',\n",
       " 't2_opening_kill_ratio_std',\n",
       " 't2_opening_kill_rating_mean',\n",
       " 't2_opening_kill_rating_std',\n",
       " 't2_team_win_percent_after_first_kill_mean',\n",
       " 't2_team_win_percent_after_first_kill_std',\n",
       " 't2_first_kill_in_won_rounds_mean',\n",
       " 't2_first_kill_in_won_rounds_std',\n",
       " 'map_id_0',\n",
       " 'map_id_1',\n",
       " 'map_id_2',\n",
       " 'map_id_3',\n",
       " 'map_id_4',\n",
       " 'map_id_5',\n",
       " 'map_id_6',\n",
       " 'map_id_7',\n",
       " 'map_id_8',\n",
       " 'map_id_9',\n",
       " 'map_id_10',\n",
       " 'map_id_11',\n",
       " 'map_id_12',\n",
       " 'map_id_13',\n",
       " 'map_id_14',\n",
       " 'map_id_15',\n",
       " 'map_id_16',\n",
       " 'map_id_17',\n",
       " 'map_id_19',\n",
       " 'map_id_20',\n",
       " 'map_id_22',\n",
       " 'map_id_23',\n",
       " 'map_id_24',\n",
       " 'map_id_25',\n",
       " 'map_id_26',\n",
       " 'map_id_27',\n",
       " 'map_id_28',\n",
       " 'map_id_29',\n",
       " 'map_id_30',\n",
       " 'map_id_31',\n",
       " 'map_id_32',\n",
       " 'map_id_33',\n",
       " 'map_id_34',\n",
       " 'map_id_35',\n",
       " 'map_id_36',\n",
       " 'map_id_37',\n",
       " 'map_id_38',\n",
       " 'map_id_39',\n",
       " 'map_id_40',\n",
       " 'map_id_41',\n",
       " 'map_id_42',\n",
       " 'map_id_43',\n",
       " 'map_id_44',\n",
       " 'map_id_45',\n",
       " 'map_id_46',\n",
       " 'map_id_47',\n",
       " 'map_id_48',\n",
       " 'map_id_49',\n",
       " 'map_id_50',\n",
       " 'map_id_51',\n",
       " 'map_id_52',\n",
       " 'map_id_53',\n",
       " 'map_id_54',\n",
       " 'map_id_55',\n",
       " 'map_id_56',\n",
       " 'map_id_57',\n",
       " 'map_id_58',\n",
       " 'map_id_59',\n",
       " 'map_id_60',\n",
       " 'map_id_61',\n",
       " 'map_id_62',\n",
       " 'map_id_63',\n",
       " 'map_id_64',\n",
       " 'map_id_65',\n",
       " 'map_id_66',\n",
       " 'map_id_67',\n",
       " 'map_id_68',\n",
       " 'map_id_69',\n",
       " 'map_id_70',\n",
       " 'map_id_71',\n",
       " 'map_id_72',\n",
       " 'map_id_73',\n",
       " 'map_id_74',\n",
       " 'map_id_75',\n",
       " 'map_id_76',\n",
       " 'map_id_77',\n",
       " 'map_id_78',\n",
       " 'map_id_79',\n",
       " 'map_id_80',\n",
       " 'map_id_81',\n",
       " 'map_id_82',\n",
       " 'map_id_83',\n",
       " 'map_id_84',\n",
       " 'map_id_85',\n",
       " 'map_id_86',\n",
       " 'map_id_87',\n",
       " 'map_id_88',\n",
       " 'map_id_89',\n",
       " 'map_id_90',\n",
       " 'map_id_91',\n",
       " 'map_id_92',\n",
       " 'map_id_93',\n",
       " 'map_id_94',\n",
       " 'map_id_95',\n",
       " 'map_id_96',\n",
       " 'map_id_97',\n",
       " 'map_id_98',\n",
       " 'map_id_99',\n",
       " 'map_id_100',\n",
       " 'map_id_101',\n",
       " 'map_id_102',\n",
       " 'map_id_103',\n",
       " 'map_id_104',\n",
       " 'map_id_105',\n",
       " 'map_id_106',\n",
       " 'map_id_107',\n",
       " 'map_id_108',\n",
       " 'map_id_109',\n",
       " 'map_id_110',\n",
       " 'map_id_111',\n",
       " 'map_id_112',\n",
       " 'map_id_113',\n",
       " 'map_id_114',\n",
       " 'map_id_115',\n",
       " 'map_id_116',\n",
       " 'map_id_117',\n",
       " 'map_id_118',\n",
       " 'map_id_119',\n",
       " 'map_id_120',\n",
       " 'map_id_122',\n",
       " 'map_id_123',\n",
       " 'map_id_124',\n",
       " 'map_id_125',\n",
       " 'map_id_126',\n",
       " 'map_id_127',\n",
       " 'map_id_128',\n",
       " 'map_id_129',\n",
       " 'map_id_130',\n",
       " 'map_id_131',\n",
       " 'map_id_132',\n",
       " 'map_id_133',\n",
       " 'map_id_134',\n",
       " 'map_id_135',\n",
       " 'map_id_136',\n",
       " 'map_id_137',\n",
       " 'map_id_138',\n",
       " 'map_id_139',\n",
       " 'map_id_140',\n",
       " 'map_id_141',\n",
       " 'map_id_142',\n",
       " 'map_id_143',\n",
       " 'map_id_144',\n",
       " 'map_id_145',\n",
       " 'map_id_146',\n",
       " 'map_id_147',\n",
       " 'map_id_148',\n",
       " 'map_id_149',\n",
       " 'map_id_150',\n",
       " 'map_id_151',\n",
       " 'map_id_152',\n",
       " 'map_id_153',\n",
       " 'map_id_154',\n",
       " 'map_id_155',\n",
       " 'map_id_156',\n",
       " 'map_id_157',\n",
       " 'map_id_158',\n",
       " 'map_id_159',\n",
       " 'map_id_160',\n",
       " 'map_id_161',\n",
       " 'map_id_162',\n",
       " 'map_id_163',\n",
       " 'map_id_164',\n",
       " 'map_id_165',\n",
       " 'map_id_166',\n",
       " 'map_id_167',\n",
       " 'map_id_168',\n",
       " 'map_id_169',\n",
       " 'map_id_170',\n",
       " 'map_id_171',\n",
       " 'map_id_172',\n",
       " 'map_id_173',\n",
       " 'map_id_174',\n",
       " 'map_id_175',\n",
       " 'map_id_176',\n",
       " 'map_id_177',\n",
       " 'map_id_178',\n",
       " 'map_id_179',\n",
       " 'map_id_180',\n",
       " 'map_id_181',\n",
       " 'map_id_182',\n",
       " 'map_id_183',\n",
       " 'map_id_184',\n",
       " 'map_id_185',\n",
       " 'map_id_186',\n",
       " 'map_id_187',\n",
       " 'map_id_188',\n",
       " 'map_id_189',\n",
       " 'map_id_190',\n",
       " 'map_id_191',\n",
       " 'map_id_192',\n",
       " 'map_id_193',\n",
       " 'map_id_195',\n",
       " 'map_id_196',\n",
       " 'map_id_197',\n",
       " 'map_id_198',\n",
       " 'map_id_199',\n",
       " 'map_id_200',\n",
       " 'map_id_201',\n",
       " 'map_id_202',\n",
       " 'map_id_203',\n",
       " 'map_id_204',\n",
       " 'map_id_205',\n",
       " 'map_id_206',\n",
       " 'map_id_207',\n",
       " 'map_id_208',\n",
       " 'map_id_209',\n",
       " 'map_id_210',\n",
       " 'map_id_211',\n",
       " 'map_id_213',\n",
       " 'map_id_214',\n",
       " 'map_id_215',\n",
       " 'map_id_216',\n",
       " 'map_id_217',\n",
       " 'map_id_218',\n",
       " 'map_id_219',\n",
       " 'map_id_220',\n",
       " 'map_id_221',\n",
       " 'map_id_222',\n",
       " 'map_id_223',\n",
       " 'map_id_224',\n",
       " 'map_id_225',\n",
       " 'map_id_226',\n",
       " 'map_id_227',\n",
       " 'map_id_228',\n",
       " 'map_id_229',\n",
       " 'map_id_230',\n",
       " 'map_id_231',\n",
       " 'map_id_232',\n",
       " 'map_id_233',\n",
       " 'map_id_234',\n",
       " 'map_id_235',\n",
       " 'map_id_236',\n",
       " 'map_id_237',\n",
       " 'map_id_238',\n",
       " 'map_id_239',\n",
       " 'map_id_240',\n",
       " 'map_id_241',\n",
       " 'map_id_242',\n",
       " 'map_id_243',\n",
       " 'map_id_244',\n",
       " 'map_id_245',\n",
       " 'map_id_246',\n",
       " 'map_id_247',\n",
       " 'map_id_248',\n",
       " 'map_id_249',\n",
       " 'map_id_250',\n",
       " 'map_id_251',\n",
       " 'map_id_252',\n",
       " 'map_id_253',\n",
       " 'map_id_254',\n",
       " 'map_id_255',\n",
       " 'map_id_256',\n",
       " 'map_id_257',\n",
       " 'map_id_258',\n",
       " 'map_id_259',\n",
       " 'map_id_260',\n",
       " 'map_id_261',\n",
       " 'map_id_262',\n",
       " 'map_id_263',\n",
       " 'map_id_264',\n",
       " 'map_id_265',\n",
       " 'map_id_266',\n",
       " 'map_id_267',\n",
       " 'map_id_268',\n",
       " 'map_id_269',\n",
       " 'map_id_270',\n",
       " 'map_id_272',\n",
       " 'map_id_273',\n",
       " 'map_id_274',\n",
       " 'map_id_276',\n",
       " 'map_id_277',\n",
       " 'map_id_278',\n",
       " 'map_id_279',\n",
       " 'map_id_280',\n",
       " 'map_id_281',\n",
       " 'map_id_282',\n",
       " 'map_id_283',\n",
       " 'map_id_284',\n",
       " 'map_id_285',\n",
       " 'map_id_286',\n",
       " 'map_id_287',\n",
       " 'map_id_289',\n",
       " 'map_id_290',\n",
       " 'map_id_291',\n",
       " 'map_id_292',\n",
       " 'map_id_293',\n",
       " 'map_id_294',\n",
       " 'map_id_295',\n",
       " 'map_id_296',\n",
       " 'map_id_297',\n",
       " 'map_id_298',\n",
       " 'map_id_299',\n",
       " 'map_id_300',\n",
       " 'map_id_301',\n",
       " 'map_id_302',\n",
       " 'map_id_303',\n",
       " 'map_id_304',\n",
       " 'map_id_305',\n",
       " 'map_id_306',\n",
       " 'map_id_307',\n",
       " 'map_id_308',\n",
       " 'map_id_309',\n",
       " 'map_id_310',\n",
       " 'map_id_311',\n",
       " 'map_id_312',\n",
       " 'map_id_313',\n",
       " 'map_id_314',\n",
       " 'map_id_315',\n",
       " 'map_id_316',\n",
       " 'map_id_317',\n",
       " 'map_id_318',\n",
       " 'map_id_319',\n",
       " 'map_id_320',\n",
       " 'map_id_321',\n",
       " 'map_id_322',\n",
       " 'map_id_323',\n",
       " 'map_id_324',\n",
       " 'map_id_325',\n",
       " 'map_id_326',\n",
       " 'map_id_327',\n",
       " 'map_id_328',\n",
       " 'map_id_329',\n",
       " 'map_id_330',\n",
       " 'map_id_331',\n",
       " 'map_id_332',\n",
       " 'map_id_333',\n",
       " 'map_id_334',\n",
       " 'map_id_335',\n",
       " 'map_id_336',\n",
       " 'map_id_337',\n",
       " 'map_id_338',\n",
       " 'map_id_339',\n",
       " 'map_id_340',\n",
       " 'map_id_341',\n",
       " 'map_id_342',\n",
       " 'map_id_343',\n",
       " 'map_id_344',\n",
       " 'map_id_345',\n",
       " 'map_id_346',\n",
       " 'map_id_347',\n",
       " 'map_id_348',\n",
       " 'map_id_349',\n",
       " 'map_id_350',\n",
       " 'map_id_351',\n",
       " 'map_id_352',\n",
       " 'map_id_353',\n",
       " 'map_id_354',\n",
       " 'map_id_355',\n",
       " 'map_id_356',\n",
       " 'map_id_357',\n",
       " 'map_id_358',\n",
       " 'map_id_359',\n",
       " 'map_id_360',\n",
       " 'map_id_361',\n",
       " 'map_id_362',\n",
       " 'map_id_363',\n",
       " 'map_id_364',\n",
       " 'map_id_365',\n",
       " 'map_id_366',\n",
       " 'map_id_367',\n",
       " 'map_id_369',\n",
       " 'map_id_370',\n",
       " 'map_id_371',\n",
       " 'map_id_372',\n",
       " 'map_id_373',\n",
       " 'map_id_374',\n",
       " 'map_id_375',\n",
       " 'map_id_376',\n",
       " 'map_id_377',\n",
       " 'map_id_378',\n",
       " 'map_id_379',\n",
       " 'map_id_380',\n",
       " 'map_id_381',\n",
       " 'map_id_382',\n",
       " 'map_id_383',\n",
       " 'map_id_384',\n",
       " 'map_id_385',\n",
       " 'map_id_387',\n",
       " 'map_id_389',\n",
       " 'map_id_390',\n",
       " 'map_id_391',\n",
       " 'map_id_392',\n",
       " 'map_id_393',\n",
       " 'map_id_394',\n",
       " 'map_id_395',\n",
       " 'map_id_396',\n",
       " 'map_id_397',\n",
       " 'map_id_398',\n",
       " 'map_id_399',\n",
       " 'map_id_400',\n",
       " 'map_id_401',\n",
       " 'map_id_402',\n",
       " 'map_id_403',\n",
       " 'map_id_404',\n",
       " 'map_id_405',\n",
       " 'map_id_406',\n",
       " 'map_id_407',\n",
       " 'map_id_408',\n",
       " 'map_id_409',\n",
       " 'map_id_410',\n",
       " 'map_id_411',\n",
       " 'map_id_412',\n",
       " 'map_id_413',\n",
       " 'map_id_414',\n",
       " 'map_id_415',\n",
       " 'map_id_416',\n",
       " 'map_id_417',\n",
       " 'map_id_418',\n",
       " 'map_id_419',\n",
       " 'map_id_420',\n",
       " 'map_id_421',\n",
       " 'map_id_422',\n",
       " 'map_id_423',\n",
       " 'map_id_424',\n",
       " 'map_id_425',\n",
       " 'map_id_427',\n",
       " 'map_id_428',\n",
       " 'map_id_429',\n",
       " 'map_id_430',\n",
       " 'map_id_431',\n",
       " 'map_id_432',\n",
       " 'map_id_433',\n",
       " 'map_id_434',\n",
       " 'map_id_435',\n",
       " 'map_id_436',\n",
       " 'map_id_437',\n",
       " 'map_id_438',\n",
       " 'map_id_439',\n",
       " 'map_id_440',\n",
       " 'map_id_441',\n",
       " 'map_id_442',\n",
       " 'map_id_443',\n",
       " 'map_id_444',\n",
       " 'map_id_445',\n",
       " 'map_id_446',\n",
       " 'map_id_447',\n",
       " 'map_id_448',\n",
       " 'map_id_449',\n",
       " 'map_id_450',\n",
       " 'map_id_451',\n",
       " 'map_id_452',\n",
       " 'map_id_453',\n",
       " 'map_id_454',\n",
       " 'map_id_455',\n",
       " 'map_id_456',\n",
       " 'map_id_457',\n",
       " 'map_id_458',\n",
       " 'map_id_459',\n",
       " 'map_id_460',\n",
       " 'map_id_461',\n",
       " 'map_id_462',\n",
       " 'map_id_463',\n",
       " 'map_id_464',\n",
       " 'map_id_465',\n",
       " 'map_id_466',\n",
       " 'map_id_467',\n",
       " 'map_id_468',\n",
       " 'map_id_469',\n",
       " 'map_id_470',\n",
       " 'map_id_471',\n",
       " 'map_id_472',\n",
       " 'map_id_473',\n",
       " 'map_id_474',\n",
       " 'map_id_475',\n",
       " 'map_id_476',\n",
       " 'map_id_477',\n",
       " 'map_id_478',\n",
       " 'map_id_479',\n",
       " 'map_id_480',\n",
       " 'map_id_481',\n",
       " 'map_id_482',\n",
       " 'map_id_483',\n",
       " 'map_id_484',\n",
       " 'map_id_485',\n",
       " 'map_id_486',\n",
       " 'map_id_487',\n",
       " 'map_id_488',\n",
       " 'map_id_489',\n",
       " 'map_id_490',\n",
       " 'map_id_491',\n",
       " 'map_id_492',\n",
       " 'map_id_493',\n",
       " 'map_id_494',\n",
       " 'map_id_495',\n",
       " 'map_id_496',\n",
       " 'map_id_497',\n",
       " 'map_id_498',\n",
       " 'map_id_499',\n",
       " 'map_id_501',\n",
       " 'map_id_502',\n",
       " 'map_id_503',\n",
       " 'map_id_504',\n",
       " 'map_id_505',\n",
       " 'map_id_506',\n",
       " 'map_id_507',\n",
       " 'map_id_508',\n",
       " 'map_id_509',\n",
       " 'map_id_510',\n",
       " 'map_id_511',\n",
       " 'map_id_512',\n",
       " 'map_id_513',\n",
       " 'map_id_514',\n",
       " 'map_id_515',\n",
       " 'map_id_516',\n",
       " 'map_id_517',\n",
       " 'map_id_518',\n",
       " 'map_id_519',\n",
       " 'map_id_520',\n",
       " 'map_id_521',\n",
       " 'map_id_522',\n",
       " 'map_id_523',\n",
       " 'map_id_524',\n",
       " 'map_id_525',\n",
       " 'map_id_526',\n",
       " 'map_id_527',\n",
       " 'map_id_528',\n",
       " 'map_id_529',\n",
       " 'map_id_530',\n",
       " 'map_id_531',\n",
       " 'map_id_532',\n",
       " 'map_id_533',\n",
       " 'map_id_534',\n",
       " 'map_id_535',\n",
       " 'map_id_536',\n",
       " 'map_id_537',\n",
       " 'map_id_538',\n",
       " 'map_id_539',\n",
       " 'map_id_540',\n",
       " 'map_id_541',\n",
       " 'map_id_542',\n",
       " 'map_id_543',\n",
       " 'map_id_544',\n",
       " 'map_id_545',\n",
       " 'map_id_546',\n",
       " 'map_id_547',\n",
       " 'map_id_548',\n",
       " 'map_id_549',\n",
       " 'map_id_550',\n",
       " 'map_id_551',\n",
       " 'map_id_552',\n",
       " 'map_id_553',\n",
       " 'map_id_554',\n",
       " 'map_id_555',\n",
       " 'map_id_556',\n",
       " 'map_id_557',\n",
       " 'map_id_558',\n",
       " 'map_id_559',\n",
       " 'map_id_560',\n",
       " 'map_id_561',\n",
       " 'map_id_562',\n",
       " 'map_id_563',\n",
       " 'map_id_564',\n",
       " 'map_id_565',\n",
       " 'map_id_567',\n",
       " 'map_id_568',\n",
       " 'map_id_569',\n",
       " 'map_id_570',\n",
       " 'map_id_571',\n",
       " 'map_id_572',\n",
       " 'map_id_573',\n",
       " 'map_id_574',\n",
       " 'map_id_575',\n",
       " 'map_id_576',\n",
       " 'map_id_577',\n",
       " 'map_id_578',\n",
       " 'map_id_579',\n",
       " 'map_id_580',\n",
       " 'map_id_581',\n",
       " 'map_id_582',\n",
       " 'map_id_583',\n",
       " 'map_id_584',\n",
       " 'map_id_585',\n",
       " 'map_id_586',\n",
       " 'map_id_587',\n",
       " 'map_id_588',\n",
       " 'map_id_589',\n",
       " 'map_id_590',\n",
       " 'map_id_591',\n",
       " 'map_id_592',\n",
       " 'map_id_593',\n",
       " 'map_id_594',\n",
       " 'map_id_595',\n",
       " 'map_id_596',\n",
       " 'map_id_597',\n",
       " 'map_id_598',\n",
       " 'map_id_599',\n",
       " 'map_id_600',\n",
       " 'map_id_601',\n",
       " 'map_id_602',\n",
       " 'map_id_603',\n",
       " 'map_id_604',\n",
       " 'map_id_605',\n",
       " 'map_id_606',\n",
       " 'map_id_607',\n",
       " 'map_id_608',\n",
       " 'map_id_609',\n",
       " 'map_id_610',\n",
       " 'map_id_611',\n",
       " 'map_id_612',\n",
       " 'map_id_613',\n",
       " 'map_id_614',\n",
       " 'map_id_615',\n",
       " 'map_id_616',\n",
       " 'map_id_617',\n",
       " 'map_id_618',\n",
       " 'map_id_619',\n",
       " 'map_id_620',\n",
       " 'map_id_621',\n",
       " 'map_id_622',\n",
       " 'map_id_623',\n",
       " 'map_id_624',\n",
       " 'map_id_625',\n",
       " 'map_id_626',\n",
       " 'map_id_627',\n",
       " 'map_id_628',\n",
       " 'map_id_629',\n",
       " 'map_id_630',\n",
       " 'map_id_631',\n",
       " 'map_id_632',\n",
       " 'map_id_633',\n",
       " 'map_id_634',\n",
       " 'map_id_635',\n",
       " 'map_id_636',\n",
       " 'map_id_637',\n",
       " 'map_id_638',\n",
       " 'map_id_639',\n",
       " 'map_id_640',\n",
       " 'map_id_641',\n",
       " 'map_id_642',\n",
       " 'map_id_643',\n",
       " 'map_id_644',\n",
       " 'map_id_645',\n",
       " 'map_id_646',\n",
       " 'map_id_647',\n",
       " 'map_id_648',\n",
       " 'map_id_649',\n",
       " 'map_id_650',\n",
       " 'map_id_651',\n",
       " 'map_id_652',\n",
       " 'map_id_653',\n",
       " 'map_id_654',\n",
       " 'map_id_655',\n",
       " 'map_id_656',\n",
       " 'map_id_657',\n",
       " 'map_id_658',\n",
       " 'map_id_659',\n",
       " 'map_id_660',\n",
       " 'map_id_661',\n",
       " 'map_id_662',\n",
       " 'map_id_663',\n",
       " 'map_id_664',\n",
       " 'map_id_665',\n",
       " 'map_id_666',\n",
       " 'map_id_667',\n",
       " 'map_id_668',\n",
       " 'map_id_669',\n",
       " 'map_id_671',\n",
       " 'map_id_672',\n",
       " 'map_id_673',\n",
       " 'map_id_674',\n",
       " 'map_id_675',\n",
       " 'map_id_676',\n",
       " 'map_id_677',\n",
       " 'map_id_678',\n",
       " 'map_id_679',\n",
       " 'map_id_681',\n",
       " 'map_id_682',\n",
       " 'map_id_683',\n",
       " 'map_id_684',\n",
       " 'map_id_685',\n",
       " 'map_id_686',\n",
       " 'map_id_687',\n",
       " 'map_id_688',\n",
       " 'map_id_689',\n",
       " 'map_id_690',\n",
       " 'map_id_691',\n",
       " 'map_id_692',\n",
       " 'map_id_693',\n",
       " 'map_id_694',\n",
       " 'map_id_695',\n",
       " 'map_id_696',\n",
       " 'map_id_697',\n",
       " 'map_id_698',\n",
       " 'map_id_699',\n",
       " 'map_id_700',\n",
       " 'map_id_701',\n",
       " 'map_id_702',\n",
       " 'map_id_703',\n",
       " 'map_id_704',\n",
       " 'map_id_705',\n",
       " 'map_id_706',\n",
       " 'map_id_707',\n",
       " 'map_id_708',\n",
       " 'map_id_709',\n",
       " 'map_id_710',\n",
       " 'map_id_711',\n",
       " 'map_id_712',\n",
       " 'map_id_713',\n",
       " 'map_id_714',\n",
       " 'map_id_715',\n",
       " 'map_id_716',\n",
       " 'map_id_717',\n",
       " 'map_id_718',\n",
       " 'map_id_719',\n",
       " 'map_id_720',\n",
       " 'map_id_721',\n",
       " 'map_id_722',\n",
       " 'map_id_723',\n",
       " 'map_id_724',\n",
       " 'map_id_725',\n",
       " 'map_id_726',\n",
       " 'map_id_727',\n",
       " 'map_id_728',\n",
       " 'map_id_729',\n",
       " 'map_id_730',\n",
       " 'map_id_731',\n",
       " 'map_id_732',\n",
       " 'map_id_733',\n",
       " 'map_id_734',\n",
       " 'map_id_735',\n",
       " 'map_id_736',\n",
       " 'map_id_737',\n",
       " 'map_id_738',\n",
       " 'map_id_739',\n",
       " 'map_id_740',\n",
       " 'map_id_741',\n",
       " 'map_id_742',\n",
       " 'team1_id_4411',\n",
       " 'team1_id_4494',\n",
       " 'team1_id_4608',\n",
       " 'team1_id_4773',\n",
       " 'team1_id_4869',\n",
       " 'team1_id_4991',\n",
       " 'team1_id_5005',\n",
       " 'team1_id_5378',\n",
       " 'team1_id_5752',\n",
       " 'team1_id_5973',\n",
       " 'team1_id_5995',\n",
       " 'team1_id_6211',\n",
       " 'team1_id_6651',\n",
       " 'team1_id_6665',\n",
       " 'team1_id_6667',\n",
       " 'team1_id_6902',\n",
       " 'team1_id_6947',\n",
       " 'team1_id_7020',\n",
       " 'team1_id_7175',\n",
       " 'team1_id_7461',\n",
       " 'team1_id_7532',\n",
       " 'team1_id_7653',\n",
       " 'team1_id_7718',\n",
       " 'team1_id_8038',\n",
       " 'team1_id_8135',\n",
       " 'team1_id_8297',\n",
       " 'team1_id_8637',\n",
       " 'team1_id_8668',\n",
       " 'team1_id_9215',\n",
       " 'team1_id_9455',\n",
       " 'team1_id_9565',\n",
       " 'team1_id_9928',\n",
       " 'team1_id_9996',\n",
       " 'team1_id_10399',\n",
       " 'team1_id_10426',\n",
       " 'team1_id_10503',\n",
       " 'team1_id_10567',\n",
       " 'team1_id_10577',\n",
       " 'team1_id_10831',\n",
       " 'team1_id_10894',\n",
       " 'team1_id_10973',\n",
       " 'team1_id_11251',\n",
       " 'team1_id_11309',\n",
       " 'team1_id_11312',\n",
       " 'team1_id_11501',\n",
       " 'team1_id_11518',\n",
       " 'team1_id_11588',\n",
       " 'team1_id_11595',\n",
       " 'team1_id_11616',\n",
       " 'team1_id_11654',\n",
       " 'team1_id_11726',\n",
       " 'team2_id_4411',\n",
       " 'team2_id_4494',\n",
       " 'team2_id_4608',\n",
       " 'team2_id_4773',\n",
       " 'team2_id_4863',\n",
       " 'team2_id_4869',\n",
       " 'team2_id_4991',\n",
       " 'team2_id_5005',\n",
       " 'team2_id_5378',\n",
       " 'team2_id_5422',\n",
       " 'team2_id_5752',\n",
       " 'team2_id_5973',\n",
       " 'team2_id_5995',\n",
       " 'team2_id_6211',\n",
       " 'team2_id_6651',\n",
       " 'team2_id_6665',\n",
       " 'team2_id_6667',\n",
       " 'team2_id_6902',\n",
       " 'team2_id_6947',\n",
       " 'team2_id_7020',\n",
       " 'team2_id_7175',\n",
       " 'team2_id_7234',\n",
       " 'team2_id_7461',\n",
       " 'team2_id_7532',\n",
       " 'team2_id_7653',\n",
       " 'team2_id_7718',\n",
       " 'team2_id_8038',\n",
       " 'team2_id_8135',\n",
       " 'team2_id_8297',\n",
       " 'team2_id_8637',\n",
       " 'team2_id_8668',\n",
       " 'team2_id_9215',\n",
       " 'team2_id_9287',\n",
       " 'team2_id_9455',\n",
       " 'team2_id_9565',\n",
       " 'team2_id_9799',\n",
       " 'team2_id_9943',\n",
       " 'team2_id_9996',\n",
       " 'team2_id_10333',\n",
       " 'team2_id_10399',\n",
       " 'team2_id_10426',\n",
       " 'team2_id_10503',\n",
       " 'team2_id_10567',\n",
       " 'team2_id_10577',\n",
       " 'team2_id_10831',\n",
       " 'team2_id_10894',\n",
       " 'team2_id_10973',\n",
       " 'team2_id_11044',\n",
       " 'team2_id_11135',\n",
       " 'team2_id_11251',\n",
       " 'team2_id_11309',\n",
       " 'team2_id_11312',\n",
       " 'team2_id_11501',\n",
       " 'team2_id_11518',\n",
       " 'team2_id_11585',\n",
       " 'team2_id_11588',\n",
       " 'team2_id_11595',\n",
       " 'team2_id_11654']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d412b209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04f32ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for a in X.columns:\n",
    "    i+=1\n",
    "    if 'map_id' in a:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25bf9917",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tree_test = Data_res.iloc[:, 96:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f736d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tree = X.iloc[:, 96:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b1a103c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>map_id_0</th>\n",
       "      <th>map_id_1</th>\n",
       "      <th>map_id_2</th>\n",
       "      <th>map_id_3</th>\n",
       "      <th>map_id_4</th>\n",
       "      <th>map_id_5</th>\n",
       "      <th>map_id_6</th>\n",
       "      <th>map_id_7</th>\n",
       "      <th>map_id_8</th>\n",
       "      <th>map_id_9</th>\n",
       "      <th>...</th>\n",
       "      <th>team2_id_11135</th>\n",
       "      <th>team2_id_11251</th>\n",
       "      <th>team2_id_11309</th>\n",
       "      <th>team2_id_11312</th>\n",
       "      <th>team2_id_11501</th>\n",
       "      <th>team2_id_11518</th>\n",
       "      <th>team2_id_11585</th>\n",
       "      <th>team2_id_11588</th>\n",
       "      <th>team2_id_11595</th>\n",
       "      <th>team2_id_11654</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>697 rows × 836 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     map_id_0  map_id_1  map_id_2  map_id_3  map_id_4  map_id_5  map_id_6  \\\n",
       "0           0         0         0         0         0         0         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         0         0         0   \n",
       "4           0         0         0         0         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "692         0         0         0         0         0         0         0   \n",
       "693         0         0         0         0         0         0         0   \n",
       "724         0         0         0         0         0         0         0   \n",
       "725         0         0         0         0         0         0         0   \n",
       "726         0         0         0         0         0         0         0   \n",
       "\n",
       "     map_id_7  map_id_8  map_id_9  ...  team2_id_11135  team2_id_11251  \\\n",
       "0           0         0         0  ...               0               0   \n",
       "1           0         0         0  ...               0               0   \n",
       "2           0         0         0  ...               0               0   \n",
       "3           0         0         0  ...               0               0   \n",
       "4           0         0         0  ...               0               0   \n",
       "..        ...       ...       ...  ...             ...             ...   \n",
       "692         0         0         0  ...               0               0   \n",
       "693         0         0         0  ...               0               0   \n",
       "724         0         0         0  ...               0               0   \n",
       "725         0         0         0  ...               0               0   \n",
       "726         0         0         0  ...               0               0   \n",
       "\n",
       "     team2_id_11309  team2_id_11312  team2_id_11501  team2_id_11518  \\\n",
       "0                 0               0               0               0   \n",
       "1                 0               0               0               0   \n",
       "2                 0               0               0               0   \n",
       "3                 0               0               0               0   \n",
       "4                 0               0               0               0   \n",
       "..              ...             ...             ...             ...   \n",
       "692               0               0               0               0   \n",
       "693               0               0               0               0   \n",
       "724               0               0               0               0   \n",
       "725               0               0               0               0   \n",
       "726               0               0               0               0   \n",
       "\n",
       "     team2_id_11585  team2_id_11588  team2_id_11595  team2_id_11654  \n",
       "0                 0               0               0               0  \n",
       "1                 0               0               0               0  \n",
       "2                 0               0               0               0  \n",
       "3                 0               0               0               0  \n",
       "4                 0               0               0               0  \n",
       "..              ...             ...             ...             ...  \n",
       "692               0               0               0               0  \n",
       "693               0               0               0               0  \n",
       "724               0               0               0               0  \n",
       "725               0               0               0               0  \n",
       "726               0               0               0               0  \n",
       "\n",
       "[697 rows x 836 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2958be1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tree, Y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec4b9aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00cbc29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'n_estimators':[2, 3, 4, 5, 8, 10, 20, 30], \n",
    "    'max_depth':[2, 3, 4, 5, 6, 7, 8, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "508f0463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:30] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:30] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:30] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:30] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:30] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:30] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:30] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:30] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:30] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:30] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:30] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:30] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:30] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:30] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:30] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:30] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:30] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:30] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:40] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:42] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:42] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:42] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:42] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:42] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:42] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:42] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:42] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:42] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:42] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:10:43] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:10:43] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, random_state=2,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, use_label_encoder=False,\n",
       "                                     validate_parameters=None, verbose=True,\n",
       "                                     verbosity=None),\n",
       "             param_grid={'max_depth': [2, 3, 4, 5, 6, 7, 8, 10],\n",
       "                         'n_estimators': [2, 3, 4, 5, 8, 10, 20, 30]})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(use_label_encoder=False, verbose=True, random_state=2)\n",
    "clf = GridSearchCV(model, params)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0bdf00b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4, 'n_estimators': 8}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "82eeff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(n_estimators = 8, max_depth = 4,\n",
    "                      use_label_encoder=False, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e5e706eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:43] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=4,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=8, n_jobs=8, num_parallel_tree=1, random_state=2,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cac4258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = model.predict_proba(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e030e687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6694947014732489"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train, preds_train[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e5ab9854",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0fd56906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6142857142857143"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(preds_test == y_test)/len(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bbc5ed0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = model.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f1b478c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5861326442721791"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, pred_proba[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4d0c34d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lin_res = Data_res.iloc[:, :96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2582ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lin = X.iloc[:, :96]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef918686",
   "metadata": {},
   "source": [
    "### Добавим предсказания деревьев как новый признак для линейных моделей (ранее проверялось, что линейные модели показывают лучшее качество чем деревья, однако с one_hot признаками деревья должны справляться лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "40f1147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lin['new_feature'] = model.predict_proba(X_tree)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75b30523",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lin_res['new_feature'] = model.predict_proba(X_tree_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b62e4900",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_lin, Y, test_size=0.33, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e7b90",
   "metadata": {},
   "source": [
    "## Протестируем линейную модель, данных довольно мало, поэтому она может показать хороший результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e2d9c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "55e89c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4f4c0ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladislav705/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "19b0092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = model.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c27b75fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7131521157430475"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train, preds_train[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "91ac7a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4047e8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6147186147186147"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(preds_test == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dddf1c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6fed3926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6525462962962962"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, pred_proba[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdf1ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "16b1d543",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba_res = model.predict_proba(X_lin_res)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ed412733",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_res['who_win'] = pred_proba_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b557c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_linear = Data_res.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2702939",
   "metadata": {},
   "source": [
    "### Линейные модели в совокупности с деревьями дали ROC_AUC 0.65"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e05bb5",
   "metadata": {},
   "source": [
    "## Попробуем добавить нелинейности с помощью нейросетей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "82524a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = X_train.to_numpy()\n",
    "X_test_t = X_test.to_numpy()\n",
    "y_train_t = y_train\n",
    "y_test_t = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cabee5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res = X_lin_res.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "32e025a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 97)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dd99f4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(466, 97)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "26a7273f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(466, 97)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e8963532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "52a52498",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = torch.FloatTensor(X_train_t)\n",
    "X_test_t = torch.FloatTensor(X_test_t)\n",
    "y_train_t = torch.LongTensor(y_train_t)\n",
    "y_test_t = torch.LongTensor(y_test_t)\n",
    "X_res = torch.FloatTensor(X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fdecd6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_train_t.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "871a5eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "466"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a4451303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "794a0a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def init_random_seed(value=0):\n",
    "    random.seed(value)\n",
    "    np.random.seed(value)\n",
    "    torch.manual_seed(value)\n",
    "    torch.cuda.manual_seed(value)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6a0490c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_random_seed(value=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e4521ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_hidden_neurons):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(n, n_hidden_neurons)\n",
    "        self.activ1 = torch.nn.Sigmoid()\n",
    "        self.fc2 = torch.nn.Linear(n_hidden_neurons, 2)\n",
    "        self.sm = torch.nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "#         x = self.fc1(x)\n",
    "#         x = self.activ1(x)\n",
    "#         x = self.fc2(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.activ1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def inference(self, x):\n",
    "        x = self.forward(x)\n",
    "        x = self.sm(x)\n",
    "        return x\n",
    "    \n",
    "net = Net(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "03afbe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), \n",
    "                             lr=1.0e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b224c855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4805)\n",
      "train\n",
      "tensor(0.4657)\n",
      "\n",
      "tensor(0.5844)\n",
      "train\n",
      "tensor(0.5386)\n",
      "\n",
      "tensor(0.6061)\n",
      "train\n",
      "tensor(0.5622)\n",
      "\n",
      "tensor(0.6017)\n",
      "train\n",
      "tensor(0.5730)\n",
      "\n",
      "tensor(0.6017)\n",
      "train\n",
      "tensor(0.5837)\n",
      "\n",
      "tensor(0.6061)\n",
      "train\n",
      "tensor(0.5987)\n",
      "\n",
      "tensor(0.6190)\n",
      "train\n",
      "tensor(0.6030)\n",
      "\n",
      "tensor(0.6277)\n",
      "train\n",
      "tensor(0.6137)\n",
      "\n",
      "tensor(0.6364)\n",
      "train\n",
      "tensor(0.6137)\n",
      "\n",
      "tensor(0.6320)\n",
      "train\n",
      "tensor(0.6180)\n",
      "\n",
      "tensor(0.6234)\n",
      "train\n",
      "tensor(0.6159)\n",
      "\n",
      "tensor(0.6234)\n",
      "train\n",
      "tensor(0.6202)\n",
      "\n",
      "tensor(0.6234)\n",
      "train\n",
      "tensor(0.6159)\n",
      "\n",
      "tensor(0.6104)\n",
      "train\n",
      "tensor(0.6223)\n",
      "\n",
      "tensor(0.6104)\n",
      "train\n",
      "tensor(0.6266)\n",
      "\n",
      "tensor(0.6190)\n",
      "train\n",
      "tensor(0.6524)\n",
      "\n",
      "tensor(0.6190)\n",
      "train\n",
      "tensor(0.6717)\n",
      "\n",
      "tensor(0.6190)\n",
      "train\n",
      "tensor(0.6931)\n",
      "\n",
      "tensor(0.6277)\n",
      "train\n",
      "tensor(0.7124)\n",
      "\n",
      "tensor(0.6277)\n",
      "train\n",
      "tensor(0.7082)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 150\n",
    "\n",
    "for epoch in range(2000):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    x_batch = X_train_t\n",
    "    y_batch = y_train_t\n",
    "\n",
    "    preds = net.forward(x_batch) \n",
    "\n",
    "    loss_value = loss(preds, y_batch)\n",
    "    loss_value.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "        \n",
    "    if epoch % 100 == 0:\n",
    "        test_preds = net.forward(X_test_t)\n",
    "        test_preds = test_preds.argmax(dim=1)\n",
    "        print((test_preds == y_test_t).float().mean())\n",
    "        print('train')\n",
    "        train_preds = net.forward(X_train_t)\n",
    "        train_preds = train_preds.argmax(dim=1)\n",
    "        print((train_preds == y_train_t).float().mean())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "006bc0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([231, 97])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4734bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba_test = net.inference(X_test_t)\n",
    "pred_test = pred_proba_test.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "73afcc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba_test = pred_proba_test.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "47c5a710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6652391975308641"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test_t, pred_proba_test[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2a8b46",
   "metadata": {},
   "source": [
    "### Дополнительно удалось добавить несколько пунктов к ROC_AUC однако данных мало, это может быть не существенным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9e70d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba_test = net.inference(X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9120f251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4602, 0.4560, 0.5267, 0.4665, 0.5998, 0.4783, 0.6248, 0.4515, 0.4516,\n",
       "        0.4514, 0.4561, 0.4515, 0.4516, 0.5710, 0.4516, 0.4515, 0.4531, 0.4520,\n",
       "        0.4603, 0.4537, 0.4521, 0.4516, 0.4520, 0.4514, 0.4514, 0.4638, 0.4515,\n",
       "        0.4516, 0.4525, 0.4525], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba_test[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d3bb0c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_res['who_win'] = np.array([0.4602, 0.4560, 0.5267, 0.4665, 0.5998, 0.4783, 0.6248, 0.4515, 0.4516,\n",
    "        0.4514, 0.4561, 0.4515, 0.4516, 0.5710, 0.4516, 0.4515, 0.4531, 0.4520,\n",
    "        0.4603, 0.4537, 0.4521, 0.4516, 0.4520, 0.4514, 0.4514, 0.4638, 0.4515,\n",
    "        0.4516, 0.4525, 0.4525])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ee77d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_res.to_csv('res_net.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a2ec3f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_maps = set(df_test.map_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4890ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_team1 = set(df_test.team1_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5557c04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_team2 = set(df_test.team2_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d9b84729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4411, 5752, 5973, 6665, 6667, 7020, 7718, 8297}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_team2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d9fccb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'map_id_11309'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1c064c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_res = totall_df_4[totall_df_4.who_win.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3abc70d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>map_id</th>\n",
       "      <th>team1_id</th>\n",
       "      <th>team2_id</th>\n",
       "      <th>who_win</th>\n",
       "      <th>t1_total_kills_mean</th>\n",
       "      <th>t1_total_kills_std</th>\n",
       "      <th>t1_headshots_mean</th>\n",
       "      <th>t1_headshots_std</th>\n",
       "      <th>t1_total_deaths_mean</th>\n",
       "      <th>t1_total_deaths_std</th>\n",
       "      <th>...</th>\n",
       "      <th>t2_total_opening_deaths_mean</th>\n",
       "      <th>t2_total_opening_deaths_std</th>\n",
       "      <th>t2_opening_kill_ratio_mean</th>\n",
       "      <th>t2_opening_kill_ratio_std</th>\n",
       "      <th>t2_opening_kill_rating_mean</th>\n",
       "      <th>t2_opening_kill_rating_std</th>\n",
       "      <th>t2_team_win_percent_after_first_kill_mean</th>\n",
       "      <th>t2_team_win_percent_after_first_kill_std</th>\n",
       "      <th>t2_first_kill_in_won_rounds_mean</th>\n",
       "      <th>t2_first_kill_in_won_rounds_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>309</td>\n",
       "      <td>5973</td>\n",
       "      <td>5752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.2</td>\n",
       "      <td>58.758489</td>\n",
       "      <td>41.54</td>\n",
       "      <td>11.878148</td>\n",
       "      <td>124.4</td>\n",
       "      <td>44.156993</td>\n",
       "      <td>...</td>\n",
       "      <td>22.4</td>\n",
       "      <td>9.951884</td>\n",
       "      <td>1.942</td>\n",
       "      <td>1.310197</td>\n",
       "      <td>1.142</td>\n",
       "      <td>0.149318</td>\n",
       "      <td>73.32</td>\n",
       "      <td>3.023508</td>\n",
       "      <td>15.48</td>\n",
       "      <td>4.312957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>541</td>\n",
       "      <td>5973</td>\n",
       "      <td>5752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>249.4</td>\n",
       "      <td>68.610786</td>\n",
       "      <td>42.70</td>\n",
       "      <td>8.123054</td>\n",
       "      <td>223.4</td>\n",
       "      <td>42.683018</td>\n",
       "      <td>...</td>\n",
       "      <td>26.2</td>\n",
       "      <td>14.344337</td>\n",
       "      <td>1.374</td>\n",
       "      <td>0.456491</td>\n",
       "      <td>1.058</td>\n",
       "      <td>0.125443</td>\n",
       "      <td>75.36</td>\n",
       "      <td>6.912771</td>\n",
       "      <td>14.32</td>\n",
       "      <td>4.508836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>1</td>\n",
       "      <td>8297</td>\n",
       "      <td>7020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>272.2</td>\n",
       "      <td>31.587339</td>\n",
       "      <td>42.66</td>\n",
       "      <td>7.838010</td>\n",
       "      <td>285.4</td>\n",
       "      <td>25.120510</td>\n",
       "      <td>...</td>\n",
       "      <td>24.6</td>\n",
       "      <td>16.788091</td>\n",
       "      <td>1.092</td>\n",
       "      <td>0.237941</td>\n",
       "      <td>1.024</td>\n",
       "      <td>0.152394</td>\n",
       "      <td>77.60</td>\n",
       "      <td>11.440280</td>\n",
       "      <td>14.74</td>\n",
       "      <td>5.553954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>392</td>\n",
       "      <td>8297</td>\n",
       "      <td>7020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>285.8</td>\n",
       "      <td>21.027601</td>\n",
       "      <td>40.86</td>\n",
       "      <td>9.816843</td>\n",
       "      <td>283.6</td>\n",
       "      <td>19.815146</td>\n",
       "      <td>...</td>\n",
       "      <td>27.4</td>\n",
       "      <td>15.538340</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.367336</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.372688</td>\n",
       "      <td>57.34</td>\n",
       "      <td>28.914259</td>\n",
       "      <td>10.12</td>\n",
       "      <td>5.410878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>684</td>\n",
       "      <td>8297</td>\n",
       "      <td>7020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128.6</td>\n",
       "      <td>9.264988</td>\n",
       "      <td>45.24</td>\n",
       "      <td>10.479427</td>\n",
       "      <td>117.2</td>\n",
       "      <td>11.805084</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.454257</td>\n",
       "      <td>1.140</td>\n",
       "      <td>0.462385</td>\n",
       "      <td>1.056</td>\n",
       "      <td>0.192624</td>\n",
       "      <td>74.38</td>\n",
       "      <td>15.047578</td>\n",
       "      <td>15.46</td>\n",
       "      <td>7.004456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>85</td>\n",
       "      <td>4494</td>\n",
       "      <td>4411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>261.2</td>\n",
       "      <td>62.792993</td>\n",
       "      <td>37.14</td>\n",
       "      <td>6.985871</td>\n",
       "      <td>241.4</td>\n",
       "      <td>54.529258</td>\n",
       "      <td>...</td>\n",
       "      <td>30.2</td>\n",
       "      <td>11.496086</td>\n",
       "      <td>1.002</td>\n",
       "      <td>0.145657</td>\n",
       "      <td>1.004</td>\n",
       "      <td>0.072829</td>\n",
       "      <td>73.08</td>\n",
       "      <td>13.386172</td>\n",
       "      <td>15.22</td>\n",
       "      <td>3.804944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>314</td>\n",
       "      <td>4494</td>\n",
       "      <td>4411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>313.2</td>\n",
       "      <td>18.225257</td>\n",
       "      <td>43.36</td>\n",
       "      <td>8.201122</td>\n",
       "      <td>319.6</td>\n",
       "      <td>48.812294</td>\n",
       "      <td>...</td>\n",
       "      <td>37.4</td>\n",
       "      <td>17.647663</td>\n",
       "      <td>1.168</td>\n",
       "      <td>0.437877</td>\n",
       "      <td>1.038</td>\n",
       "      <td>0.158921</td>\n",
       "      <td>73.28</td>\n",
       "      <td>8.224695</td>\n",
       "      <td>15.28</td>\n",
       "      <td>4.814727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>403</td>\n",
       "      <td>4494</td>\n",
       "      <td>4411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300.4</td>\n",
       "      <td>47.407172</td>\n",
       "      <td>48.44</td>\n",
       "      <td>8.588737</td>\n",
       "      <td>292.8</td>\n",
       "      <td>40.434639</td>\n",
       "      <td>...</td>\n",
       "      <td>27.8</td>\n",
       "      <td>7.520638</td>\n",
       "      <td>1.086</td>\n",
       "      <td>0.418693</td>\n",
       "      <td>1.030</td>\n",
       "      <td>0.176522</td>\n",
       "      <td>71.24</td>\n",
       "      <td>6.543577</td>\n",
       "      <td>15.24</td>\n",
       "      <td>5.883400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>125</td>\n",
       "      <td>4608</td>\n",
       "      <td>7718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>247.8</td>\n",
       "      <td>38.690567</td>\n",
       "      <td>50.78</td>\n",
       "      <td>7.039432</td>\n",
       "      <td>218.4</td>\n",
       "      <td>19.064102</td>\n",
       "      <td>...</td>\n",
       "      <td>36.4</td>\n",
       "      <td>17.106724</td>\n",
       "      <td>1.106</td>\n",
       "      <td>0.199860</td>\n",
       "      <td>1.022</td>\n",
       "      <td>0.155358</td>\n",
       "      <td>76.74</td>\n",
       "      <td>3.211604</td>\n",
       "      <td>14.90</td>\n",
       "      <td>6.011655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>241</td>\n",
       "      <td>4608</td>\n",
       "      <td>7718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397.2</td>\n",
       "      <td>79.393703</td>\n",
       "      <td>47.32</td>\n",
       "      <td>10.005678</td>\n",
       "      <td>350.2</td>\n",
       "      <td>24.514486</td>\n",
       "      <td>...</td>\n",
       "      <td>33.6</td>\n",
       "      <td>8.138796</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.349148</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.111104</td>\n",
       "      <td>76.30</td>\n",
       "      <td>10.585273</td>\n",
       "      <td>14.36</td>\n",
       "      <td>2.366094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>489</td>\n",
       "      <td>4608</td>\n",
       "      <td>7718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156.6</td>\n",
       "      <td>24.483464</td>\n",
       "      <td>47.56</td>\n",
       "      <td>9.614697</td>\n",
       "      <td>128.0</td>\n",
       "      <td>27.261695</td>\n",
       "      <td>...</td>\n",
       "      <td>30.8</td>\n",
       "      <td>6.554388</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.318559</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.128592</td>\n",
       "      <td>70.34</td>\n",
       "      <td>13.461887</td>\n",
       "      <td>12.96</td>\n",
       "      <td>4.956854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>678</td>\n",
       "      <td>6665</td>\n",
       "      <td>6667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>370.4</td>\n",
       "      <td>76.017366</td>\n",
       "      <td>41.96</td>\n",
       "      <td>9.193171</td>\n",
       "      <td>369.0</td>\n",
       "      <td>67.696381</td>\n",
       "      <td>...</td>\n",
       "      <td>41.2</td>\n",
       "      <td>14.702381</td>\n",
       "      <td>1.242</td>\n",
       "      <td>0.581735</td>\n",
       "      <td>1.030</td>\n",
       "      <td>0.115758</td>\n",
       "      <td>74.60</td>\n",
       "      <td>5.187292</td>\n",
       "      <td>14.90</td>\n",
       "      <td>4.621688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>334</td>\n",
       "      <td>6665</td>\n",
       "      <td>6667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143.8</td>\n",
       "      <td>40.454419</td>\n",
       "      <td>41.20</td>\n",
       "      <td>10.507521</td>\n",
       "      <td>149.0</td>\n",
       "      <td>35.524639</td>\n",
       "      <td>...</td>\n",
       "      <td>57.2</td>\n",
       "      <td>24.766106</td>\n",
       "      <td>1.302</td>\n",
       "      <td>0.433008</td>\n",
       "      <td>1.034</td>\n",
       "      <td>0.042237</td>\n",
       "      <td>69.98</td>\n",
       "      <td>4.833798</td>\n",
       "      <td>13.50</td>\n",
       "      <td>1.528398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>216</td>\n",
       "      <td>5973</td>\n",
       "      <td>8297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>266.4</td>\n",
       "      <td>80.599256</td>\n",
       "      <td>40.58</td>\n",
       "      <td>7.927269</td>\n",
       "      <td>255.6</td>\n",
       "      <td>77.507677</td>\n",
       "      <td>...</td>\n",
       "      <td>24.4</td>\n",
       "      <td>11.412274</td>\n",
       "      <td>1.180</td>\n",
       "      <td>0.232293</td>\n",
       "      <td>1.030</td>\n",
       "      <td>0.084617</td>\n",
       "      <td>75.28</td>\n",
       "      <td>3.712358</td>\n",
       "      <td>15.30</td>\n",
       "      <td>4.410896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>143</td>\n",
       "      <td>5973</td>\n",
       "      <td>8297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230.6</td>\n",
       "      <td>20.606795</td>\n",
       "      <td>45.78</td>\n",
       "      <td>8.028549</td>\n",
       "      <td>205.4</td>\n",
       "      <td>8.260751</td>\n",
       "      <td>...</td>\n",
       "      <td>41.2</td>\n",
       "      <td>16.606023</td>\n",
       "      <td>1.162</td>\n",
       "      <td>0.331566</td>\n",
       "      <td>1.036</td>\n",
       "      <td>0.153701</td>\n",
       "      <td>74.10</td>\n",
       "      <td>6.934551</td>\n",
       "      <td>15.44</td>\n",
       "      <td>6.127512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>413</td>\n",
       "      <td>4494</td>\n",
       "      <td>6665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>312.2</td>\n",
       "      <td>41.431389</td>\n",
       "      <td>47.90</td>\n",
       "      <td>8.386418</td>\n",
       "      <td>299.0</td>\n",
       "      <td>37.868192</td>\n",
       "      <td>...</td>\n",
       "      <td>46.8</td>\n",
       "      <td>19.792928</td>\n",
       "      <td>1.050</td>\n",
       "      <td>0.266308</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.082073</td>\n",
       "      <td>74.08</td>\n",
       "      <td>7.074009</td>\n",
       "      <td>14.64</td>\n",
       "      <td>3.061111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>466</td>\n",
       "      <td>4494</td>\n",
       "      <td>6665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>379.0</td>\n",
       "      <td>28.368997</td>\n",
       "      <td>45.28</td>\n",
       "      <td>8.037263</td>\n",
       "      <td>364.0</td>\n",
       "      <td>50.687277</td>\n",
       "      <td>...</td>\n",
       "      <td>45.6</td>\n",
       "      <td>17.715530</td>\n",
       "      <td>1.276</td>\n",
       "      <td>0.362966</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.098509</td>\n",
       "      <td>77.46</td>\n",
       "      <td>5.450358</td>\n",
       "      <td>15.38</td>\n",
       "      <td>3.896871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>45</td>\n",
       "      <td>4494</td>\n",
       "      <td>6665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>272.2</td>\n",
       "      <td>81.100925</td>\n",
       "      <td>41.02</td>\n",
       "      <td>8.820748</td>\n",
       "      <td>235.4</td>\n",
       "      <td>75.706275</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>20.947554</td>\n",
       "      <td>1.094</td>\n",
       "      <td>0.234742</td>\n",
       "      <td>1.026</td>\n",
       "      <td>0.147187</td>\n",
       "      <td>71.76</td>\n",
       "      <td>5.259125</td>\n",
       "      <td>14.54</td>\n",
       "      <td>5.904100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>518</td>\n",
       "      <td>7718</td>\n",
       "      <td>5973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225.8</td>\n",
       "      <td>19.093454</td>\n",
       "      <td>43.66</td>\n",
       "      <td>10.236132</td>\n",
       "      <td>226.4</td>\n",
       "      <td>18.488916</td>\n",
       "      <td>...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>7.183314</td>\n",
       "      <td>1.118</td>\n",
       "      <td>0.334509</td>\n",
       "      <td>1.010</td>\n",
       "      <td>0.145465</td>\n",
       "      <td>69.02</td>\n",
       "      <td>4.369622</td>\n",
       "      <td>13.62</td>\n",
       "      <td>4.159519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>220</td>\n",
       "      <td>7718</td>\n",
       "      <td>5973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>286.8</td>\n",
       "      <td>30.314353</td>\n",
       "      <td>46.24</td>\n",
       "      <td>8.146803</td>\n",
       "      <td>285.0</td>\n",
       "      <td>14.764823</td>\n",
       "      <td>...</td>\n",
       "      <td>34.2</td>\n",
       "      <td>14.620534</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.306555</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.096250</td>\n",
       "      <td>72.52</td>\n",
       "      <td>8.057394</td>\n",
       "      <td>15.50</td>\n",
       "      <td>3.517954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>614</td>\n",
       "      <td>7718</td>\n",
       "      <td>5973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>254.0</td>\n",
       "      <td>23.486166</td>\n",
       "      <td>43.10</td>\n",
       "      <td>9.408719</td>\n",
       "      <td>253.2</td>\n",
       "      <td>27.374441</td>\n",
       "      <td>...</td>\n",
       "      <td>33.4</td>\n",
       "      <td>10.287857</td>\n",
       "      <td>1.064</td>\n",
       "      <td>0.223482</td>\n",
       "      <td>1.030</td>\n",
       "      <td>0.137840</td>\n",
       "      <td>70.62</td>\n",
       "      <td>11.658199</td>\n",
       "      <td>14.36</td>\n",
       "      <td>4.006295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>246</td>\n",
       "      <td>4608</td>\n",
       "      <td>6665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>196.4</td>\n",
       "      <td>28.765257</td>\n",
       "      <td>52.76</td>\n",
       "      <td>7.156144</td>\n",
       "      <td>183.0</td>\n",
       "      <td>12.853015</td>\n",
       "      <td>...</td>\n",
       "      <td>47.6</td>\n",
       "      <td>18.238421</td>\n",
       "      <td>1.298</td>\n",
       "      <td>0.403009</td>\n",
       "      <td>1.048</td>\n",
       "      <td>0.109800</td>\n",
       "      <td>77.70</td>\n",
       "      <td>4.182822</td>\n",
       "      <td>15.38</td>\n",
       "      <td>3.939239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>652</td>\n",
       "      <td>4608</td>\n",
       "      <td>6665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>415.6</td>\n",
       "      <td>82.453866</td>\n",
       "      <td>47.32</td>\n",
       "      <td>10.098594</td>\n",
       "      <td>367.4</td>\n",
       "      <td>25.996923</td>\n",
       "      <td>...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>21.137644</td>\n",
       "      <td>1.076</td>\n",
       "      <td>0.296149</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.076577</td>\n",
       "      <td>72.66</td>\n",
       "      <td>7.099183</td>\n",
       "      <td>14.78</td>\n",
       "      <td>3.007590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>86</td>\n",
       "      <td>6667</td>\n",
       "      <td>7718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>196.4</td>\n",
       "      <td>15.344054</td>\n",
       "      <td>46.72</td>\n",
       "      <td>10.144437</td>\n",
       "      <td>168.6</td>\n",
       "      <td>17.828068</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11.983322</td>\n",
       "      <td>1.104</td>\n",
       "      <td>0.348861</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.163463</td>\n",
       "      <td>73.32</td>\n",
       "      <td>7.240829</td>\n",
       "      <td>14.80</td>\n",
       "      <td>5.035077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>628</td>\n",
       "      <td>6667</td>\n",
       "      <td>7718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>264.8</td>\n",
       "      <td>23.574563</td>\n",
       "      <td>48.86</td>\n",
       "      <td>7.658355</td>\n",
       "      <td>215.8</td>\n",
       "      <td>25.158696</td>\n",
       "      <td>...</td>\n",
       "      <td>38.2</td>\n",
       "      <td>10.027961</td>\n",
       "      <td>1.180</td>\n",
       "      <td>0.602096</td>\n",
       "      <td>1.028</td>\n",
       "      <td>0.163511</td>\n",
       "      <td>73.92</td>\n",
       "      <td>5.674293</td>\n",
       "      <td>15.48</td>\n",
       "      <td>5.343931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>515</td>\n",
       "      <td>4608</td>\n",
       "      <td>6667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263.4</td>\n",
       "      <td>41.359884</td>\n",
       "      <td>50.46</td>\n",
       "      <td>6.627096</td>\n",
       "      <td>237.2</td>\n",
       "      <td>19.630588</td>\n",
       "      <td>...</td>\n",
       "      <td>60.2</td>\n",
       "      <td>25.015195</td>\n",
       "      <td>1.254</td>\n",
       "      <td>0.356348</td>\n",
       "      <td>1.030</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>69.80</td>\n",
       "      <td>3.737914</td>\n",
       "      <td>13.38</td>\n",
       "      <td>1.758863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>201</td>\n",
       "      <td>4608</td>\n",
       "      <td>6667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.6</td>\n",
       "      <td>26.119724</td>\n",
       "      <td>47.92</td>\n",
       "      <td>9.036238</td>\n",
       "      <td>141.6</td>\n",
       "      <td>28.047103</td>\n",
       "      <td>...</td>\n",
       "      <td>44.6</td>\n",
       "      <td>15.869468</td>\n",
       "      <td>1.184</td>\n",
       "      <td>0.480233</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.111427</td>\n",
       "      <td>75.22</td>\n",
       "      <td>5.106623</td>\n",
       "      <td>14.72</td>\n",
       "      <td>4.467841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>674</td>\n",
       "      <td>4608</td>\n",
       "      <td>6667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.4</td>\n",
       "      <td>24.952755</td>\n",
       "      <td>45.96</td>\n",
       "      <td>9.633400</td>\n",
       "      <td>148.0</td>\n",
       "      <td>45.598246</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.928388</td>\n",
       "      <td>1.412</td>\n",
       "      <td>0.565947</td>\n",
       "      <td>1.064</td>\n",
       "      <td>0.153180</td>\n",
       "      <td>78.60</td>\n",
       "      <td>4.572964</td>\n",
       "      <td>14.80</td>\n",
       "      <td>4.109988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>357</td>\n",
       "      <td>4608</td>\n",
       "      <td>6667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>442.0</td>\n",
       "      <td>83.744851</td>\n",
       "      <td>47.08</td>\n",
       "      <td>9.787012</td>\n",
       "      <td>393.4</td>\n",
       "      <td>25.896718</td>\n",
       "      <td>...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20.069878</td>\n",
       "      <td>1.064</td>\n",
       "      <td>0.520715</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.111427</td>\n",
       "      <td>76.60</td>\n",
       "      <td>7.071916</td>\n",
       "      <td>13.94</td>\n",
       "      <td>3.283656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>593</td>\n",
       "      <td>4608</td>\n",
       "      <td>6667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>213.6</td>\n",
       "      <td>31.283222</td>\n",
       "      <td>52.44</td>\n",
       "      <td>7.730873</td>\n",
       "      <td>194.4</td>\n",
       "      <td>13.001538</td>\n",
       "      <td>...</td>\n",
       "      <td>32.4</td>\n",
       "      <td>13.215143</td>\n",
       "      <td>1.488</td>\n",
       "      <td>0.349651</td>\n",
       "      <td>1.110</td>\n",
       "      <td>0.123612</td>\n",
       "      <td>78.58</td>\n",
       "      <td>3.946847</td>\n",
       "      <td>15.04</td>\n",
       "      <td>4.237263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     map_id  team1_id  team2_id  who_win  t1_total_kills_mean  \\\n",
       "694     309      5973      5752      NaN                145.2   \n",
       "695     541      5973      5752      NaN                249.4   \n",
       "696       1      8297      7020      NaN                272.2   \n",
       "697     392      8297      7020      NaN                285.8   \n",
       "698     684      8297      7020      NaN                128.6   \n",
       "699      85      4494      4411      NaN                261.2   \n",
       "700     314      4494      4411      NaN                313.2   \n",
       "701     403      4494      4411      NaN                300.4   \n",
       "702     125      4608      7718      NaN                247.8   \n",
       "703     241      4608      7718      NaN                397.2   \n",
       "704     489      4608      7718      NaN                156.6   \n",
       "705     678      6665      6667      NaN                370.4   \n",
       "706     334      6665      6667      NaN                143.8   \n",
       "707     216      5973      8297      NaN                266.4   \n",
       "708     143      5973      8297      NaN                230.6   \n",
       "709     413      4494      6665      NaN                312.2   \n",
       "710     466      4494      6665      NaN                379.0   \n",
       "711      45      4494      6665      NaN                272.2   \n",
       "712     518      7718      5973      NaN                225.8   \n",
       "713     220      7718      5973      NaN                286.8   \n",
       "714     614      7718      5973      NaN                254.0   \n",
       "715     246      4608      6665      NaN                196.4   \n",
       "716     652      4608      6665      NaN                415.6   \n",
       "717      86      6667      7718      NaN                196.4   \n",
       "718     628      6667      7718      NaN                264.8   \n",
       "719     515      4608      6667      NaN                263.4   \n",
       "720     201      4608      6667      NaN                174.6   \n",
       "721     674      4608      6667      NaN                174.4   \n",
       "722     357      4608      6667      NaN                442.0   \n",
       "723     593      4608      6667      NaN                213.6   \n",
       "\n",
       "     t1_total_kills_std  t1_headshots_mean  t1_headshots_std  \\\n",
       "694           58.758489              41.54         11.878148   \n",
       "695           68.610786              42.70          8.123054   \n",
       "696           31.587339              42.66          7.838010   \n",
       "697           21.027601              40.86          9.816843   \n",
       "698            9.264988              45.24         10.479427   \n",
       "699           62.792993              37.14          6.985871   \n",
       "700           18.225257              43.36          8.201122   \n",
       "701           47.407172              48.44          8.588737   \n",
       "702           38.690567              50.78          7.039432   \n",
       "703           79.393703              47.32         10.005678   \n",
       "704           24.483464              47.56          9.614697   \n",
       "705           76.017366              41.96          9.193171   \n",
       "706           40.454419              41.20         10.507521   \n",
       "707           80.599256              40.58          7.927269   \n",
       "708           20.606795              45.78          8.028549   \n",
       "709           41.431389              47.90          8.386418   \n",
       "710           28.368997              45.28          8.037263   \n",
       "711           81.100925              41.02          8.820748   \n",
       "712           19.093454              43.66         10.236132   \n",
       "713           30.314353              46.24          8.146803   \n",
       "714           23.486166              43.10          9.408719   \n",
       "715           28.765257              52.76          7.156144   \n",
       "716           82.453866              47.32         10.098594   \n",
       "717           15.344054              46.72         10.144437   \n",
       "718           23.574563              48.86          7.658355   \n",
       "719           41.359884              50.46          6.627096   \n",
       "720           26.119724              47.92          9.036238   \n",
       "721           24.952755              45.96          9.633400   \n",
       "722           83.744851              47.08          9.787012   \n",
       "723           31.283222              52.44          7.730873   \n",
       "\n",
       "     t1_total_deaths_mean  t1_total_deaths_std  ...  \\\n",
       "694                 124.4            44.156993  ...   \n",
       "695                 223.4            42.683018  ...   \n",
       "696                 285.4            25.120510  ...   \n",
       "697                 283.6            19.815146  ...   \n",
       "698                 117.2            11.805084  ...   \n",
       "699                 241.4            54.529258  ...   \n",
       "700                 319.6            48.812294  ...   \n",
       "701                 292.8            40.434639  ...   \n",
       "702                 218.4            19.064102  ...   \n",
       "703                 350.2            24.514486  ...   \n",
       "704                 128.0            27.261695  ...   \n",
       "705                 369.0            67.696381  ...   \n",
       "706                 149.0            35.524639  ...   \n",
       "707                 255.6            77.507677  ...   \n",
       "708                 205.4             8.260751  ...   \n",
       "709                 299.0            37.868192  ...   \n",
       "710                 364.0            50.687277  ...   \n",
       "711                 235.4            75.706275  ...   \n",
       "712                 226.4            18.488916  ...   \n",
       "713                 285.0            14.764823  ...   \n",
       "714                 253.2            27.374441  ...   \n",
       "715                 183.0            12.853015  ...   \n",
       "716                 367.4            25.996923  ...   \n",
       "717                 168.6            17.828068  ...   \n",
       "718                 215.8            25.158696  ...   \n",
       "719                 237.2            19.630588  ...   \n",
       "720                 141.6            28.047103  ...   \n",
       "721                 148.0            45.598246  ...   \n",
       "722                 393.4            25.896718  ...   \n",
       "723                 194.4            13.001538  ...   \n",
       "\n",
       "     t2_total_opening_deaths_mean  t2_total_opening_deaths_std  \\\n",
       "694                          22.4                     9.951884   \n",
       "695                          26.2                    14.344337   \n",
       "696                          24.6                    16.788091   \n",
       "697                          27.4                    15.538340   \n",
       "698                          21.0                    11.454257   \n",
       "699                          30.2                    11.496086   \n",
       "700                          37.4                    17.647663   \n",
       "701                          27.8                     7.520638   \n",
       "702                          36.4                    17.106724   \n",
       "703                          33.6                     8.138796   \n",
       "704                          30.8                     6.554388   \n",
       "705                          41.2                    14.702381   \n",
       "706                          57.2                    24.766106   \n",
       "707                          24.4                    11.412274   \n",
       "708                          41.2                    16.606023   \n",
       "709                          46.8                    19.792928   \n",
       "710                          45.6                    17.715530   \n",
       "711                          51.0                    20.947554   \n",
       "712                          37.0                     7.183314   \n",
       "713                          34.2                    14.620534   \n",
       "714                          33.4                    10.287857   \n",
       "715                          47.6                    18.238421   \n",
       "716                          49.0                    21.137644   \n",
       "717                          33.0                    11.983322   \n",
       "718                          38.2                    10.027961   \n",
       "719                          60.2                    25.015195   \n",
       "720                          44.6                    15.869468   \n",
       "721                          28.0                    13.928388   \n",
       "722                          57.0                    20.069878   \n",
       "723                          32.4                    13.215143   \n",
       "\n",
       "     t2_opening_kill_ratio_mean  t2_opening_kill_ratio_std  \\\n",
       "694                       1.942                   1.310197   \n",
       "695                       1.374                   0.456491   \n",
       "696                       1.092                   0.237941   \n",
       "697                       0.688                   0.367336   \n",
       "698                       1.140                   0.462385   \n",
       "699                       1.002                   0.145657   \n",
       "700                       1.168                   0.437877   \n",
       "701                       1.086                   0.418693   \n",
       "702                       1.106                   0.199860   \n",
       "703                       0.994                   0.349148   \n",
       "704                       0.940                   0.318559   \n",
       "705                       1.242                   0.581735   \n",
       "706                       1.302                   0.433008   \n",
       "707                       1.180                   0.232293   \n",
       "708                       1.162                   0.331566   \n",
       "709                       1.050                   0.266308   \n",
       "710                       1.276                   0.362966   \n",
       "711                       1.094                   0.234742   \n",
       "712                       1.118                   0.334509   \n",
       "713                       0.978                   0.306555   \n",
       "714                       1.064                   0.223482   \n",
       "715                       1.298                   0.403009   \n",
       "716                       1.076                   0.296149   \n",
       "717                       1.104                   0.348861   \n",
       "718                       1.180                   0.602096   \n",
       "719                       1.254                   0.356348   \n",
       "720                       1.184                   0.480233   \n",
       "721                       1.412                   0.565947   \n",
       "722                       1.064                   0.520715   \n",
       "723                       1.488                   0.349651   \n",
       "\n",
       "     t2_opening_kill_rating_mean  t2_opening_kill_rating_std  \\\n",
       "694                        1.142                    0.149318   \n",
       "695                        1.058                    0.125443   \n",
       "696                        1.024                    0.152394   \n",
       "697                        0.742                    0.372688   \n",
       "698                        1.056                    0.192624   \n",
       "699                        1.004                    0.072829   \n",
       "700                        1.038                    0.158921   \n",
       "701                        1.030                    0.176522   \n",
       "702                        1.022                    0.155358   \n",
       "703                        0.976                    0.111104   \n",
       "704                        0.962                    0.128592   \n",
       "705                        1.030                    0.115758   \n",
       "706                        1.034                    0.042237   \n",
       "707                        1.030                    0.084617   \n",
       "708                        1.036                    0.153701   \n",
       "709                        0.992                    0.082073   \n",
       "710                        1.046                    0.098509   \n",
       "711                        1.026                    0.147187   \n",
       "712                        1.010                    0.145465   \n",
       "713                        0.994                    0.096250   \n",
       "714                        1.030                    0.137840   \n",
       "715                        1.048                    0.109800   \n",
       "716                        0.996                    0.076577   \n",
       "717                        1.020                    0.163463   \n",
       "718                        1.028                    0.163511   \n",
       "719                        1.030                    0.040000   \n",
       "720                        1.018                    0.111427   \n",
       "721                        1.064                    0.153180   \n",
       "722                        0.968                    0.111427   \n",
       "723                        1.110                    0.123612   \n",
       "\n",
       "     t2_team_win_percent_after_first_kill_mean  \\\n",
       "694                                      73.32   \n",
       "695                                      75.36   \n",
       "696                                      77.60   \n",
       "697                                      57.34   \n",
       "698                                      74.38   \n",
       "699                                      73.08   \n",
       "700                                      73.28   \n",
       "701                                      71.24   \n",
       "702                                      76.74   \n",
       "703                                      76.30   \n",
       "704                                      70.34   \n",
       "705                                      74.60   \n",
       "706                                      69.98   \n",
       "707                                      75.28   \n",
       "708                                      74.10   \n",
       "709                                      74.08   \n",
       "710                                      77.46   \n",
       "711                                      71.76   \n",
       "712                                      69.02   \n",
       "713                                      72.52   \n",
       "714                                      70.62   \n",
       "715                                      77.70   \n",
       "716                                      72.66   \n",
       "717                                      73.32   \n",
       "718                                      73.92   \n",
       "719                                      69.80   \n",
       "720                                      75.22   \n",
       "721                                      78.60   \n",
       "722                                      76.60   \n",
       "723                                      78.58   \n",
       "\n",
       "     t2_team_win_percent_after_first_kill_std  \\\n",
       "694                                  3.023508   \n",
       "695                                  6.912771   \n",
       "696                                 11.440280   \n",
       "697                                 28.914259   \n",
       "698                                 15.047578   \n",
       "699                                 13.386172   \n",
       "700                                  8.224695   \n",
       "701                                  6.543577   \n",
       "702                                  3.211604   \n",
       "703                                 10.585273   \n",
       "704                                 13.461887   \n",
       "705                                  5.187292   \n",
       "706                                  4.833798   \n",
       "707                                  3.712358   \n",
       "708                                  6.934551   \n",
       "709                                  7.074009   \n",
       "710                                  5.450358   \n",
       "711                                  5.259125   \n",
       "712                                  4.369622   \n",
       "713                                  8.057394   \n",
       "714                                 11.658199   \n",
       "715                                  4.182822   \n",
       "716                                  7.099183   \n",
       "717                                  7.240829   \n",
       "718                                  5.674293   \n",
       "719                                  3.737914   \n",
       "720                                  5.106623   \n",
       "721                                  4.572964   \n",
       "722                                  7.071916   \n",
       "723                                  3.946847   \n",
       "\n",
       "     t2_first_kill_in_won_rounds_mean  t2_first_kill_in_won_rounds_std  \n",
       "694                             15.48                         4.312957  \n",
       "695                             14.32                         4.508836  \n",
       "696                             14.74                         5.553954  \n",
       "697                             10.12                         5.410878  \n",
       "698                             15.46                         7.004456  \n",
       "699                             15.22                         3.804944  \n",
       "700                             15.28                         4.814727  \n",
       "701                             15.24                         5.883400  \n",
       "702                             14.90                         6.011655  \n",
       "703                             14.36                         2.366094  \n",
       "704                             12.96                         4.956854  \n",
       "705                             14.90                         4.621688  \n",
       "706                             13.50                         1.528398  \n",
       "707                             15.30                         4.410896  \n",
       "708                             15.44                         6.127512  \n",
       "709                             14.64                         3.061111  \n",
       "710                             15.38                         3.896871  \n",
       "711                             14.54                         5.904100  \n",
       "712                             13.62                         4.159519  \n",
       "713                             15.50                         3.517954  \n",
       "714                             14.36                         4.006295  \n",
       "715                             15.38                         3.939239  \n",
       "716                             14.78                         3.007590  \n",
       "717                             14.80                         5.035077  \n",
       "718                             15.48                         5.343931  \n",
       "719                             13.38                         1.758863  \n",
       "720                             14.72                         4.467841  \n",
       "721                             14.80                         4.109988  \n",
       "722                             13.94                         3.283656  \n",
       "723                             15.04                         4.237263  \n",
       "\n",
       "[30 rows x 100 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_without_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "90526012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['map_id', 'team1_id', 'team2_id', 'who_win', 't1_total_kills_mean',\n",
       "       't1_total_kills_std', 't1_headshots_mean', 't1_headshots_std',\n",
       "       't1_total_deaths_mean', 't1_total_deaths_std', 't1_kd_ratio_mean',\n",
       "       't1_kd_ratio_std', 't1_damage_per_round_mean',\n",
       "       't1_damage_per_round_std', 't1_grenade_damage_per_round_mean',\n",
       "       't1_grenade_damage_per_round_std', 't1_maps_played_mean',\n",
       "       't1_maps_played_std', 't1_rounds_played_mean', 't1_rounds_played_std',\n",
       "       't1_kills_per_round_mean', 't1_kills_per_round_std',\n",
       "       't1_assists_per_round_mean', 't1_assists_per_round_std',\n",
       "       't1_deaths_per_round_mean', 't1_deaths_per_round_std',\n",
       "       't1_saved_by_teammate_per_round_mean',\n",
       "       't1_saved_by_teammate_per_round_std',\n",
       "       't1_saved_teammates_per_round_mean', 't1_saved_teammates_per_round_std',\n",
       "       't1_rating_mean', 't1_rating_std', 't1_kill_death_mean',\n",
       "       't1_kill_death_std', 't1_kill_round_mean', 't1_kill_round_std',\n",
       "       't1_rounds_with_kills_mean', 't1_rounds_with_kills_std',\n",
       "       't1_kill_death_difference_mean', 't1_kill_death_difference_std',\n",
       "       't1_total_opening_kills_mean', 't1_total_opening_kills_std',\n",
       "       't1_total_opening_deaths_mean', 't1_total_opening_deaths_std',\n",
       "       't1_opening_kill_ratio_mean', 't1_opening_kill_ratio_std',\n",
       "       't1_opening_kill_rating_mean', 't1_opening_kill_rating_std',\n",
       "       't1_team_win_percent_after_first_kill_mean',\n",
       "       't1_team_win_percent_after_first_kill_std',\n",
       "       't1_first_kill_in_won_rounds_mean', 't1_first_kill_in_won_rounds_std',\n",
       "       't2_total_kills_mean', 't2_total_kills_std', 't2_headshots_mean',\n",
       "       't2_headshots_std', 't2_total_deaths_mean', 't2_total_deaths_std',\n",
       "       't2_kd_ratio_mean', 't2_kd_ratio_std', 't2_damage_per_round_mean',\n",
       "       't2_damage_per_round_std', 't2_grenade_damage_per_round_mean',\n",
       "       't2_grenade_damage_per_round_std', 't2_maps_played_mean',\n",
       "       't2_maps_played_std', 't2_rounds_played_mean', 't2_rounds_played_std',\n",
       "       't2_kills_per_round_mean', 't2_kills_per_round_std',\n",
       "       't2_assists_per_round_mean', 't2_assists_per_round_std',\n",
       "       't2_deaths_per_round_mean', 't2_deaths_per_round_std',\n",
       "       't2_saved_by_teammate_per_round_mean',\n",
       "       't2_saved_by_teammate_per_round_std',\n",
       "       't2_saved_teammates_per_round_mean', 't2_saved_teammates_per_round_std',\n",
       "       't2_rating_mean', 't2_rating_std', 't2_kill_death_mean',\n",
       "       't2_kill_death_std', 't2_kill_round_mean', 't2_kill_round_std',\n",
       "       't2_rounds_with_kills_mean', 't2_rounds_with_kills_std',\n",
       "       't2_kill_death_difference_mean', 't2_kill_death_difference_std',\n",
       "       't2_total_opening_kills_mean', 't2_total_opening_kills_std',\n",
       "       't2_total_opening_deaths_mean', 't2_total_opening_deaths_std',\n",
       "       't2_opening_kill_ratio_mean', 't2_opening_kill_ratio_std',\n",
       "       't2_opening_kill_rating_mean', 't2_opening_kill_rating_std',\n",
       "       't2_team_win_percent_after_first_kill_mean',\n",
       "       't2_team_win_percent_after_first_kill_std',\n",
       "       't2_first_kill_in_won_rounds_mean', 't2_first_kill_in_won_rounds_std'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_without_res.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8335db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_res = data_without_res.drop(columns=['who_win'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a9d30e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_res_net = '''select map_id, team1_id, team2_id, who_win from \n",
    "data_without_res, Data_res\n",
    "where (data_without_res.t1_total_kills_std = Data_res.t1_total_kills_std and data_without_res.t2_total_kills_std = Data_res.t2_total_kills_std)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c6385c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_res_linear = '''select map_id, team1_id, team2_id, who_win from \n",
    "data_without_res, res_linear\n",
    "where (data_without_res.t1_total_kills_std = res_linear.t1_total_kills_std and data_without_res.t2_total_kills_std = res_linear.t2_total_kills_std)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "13a71937",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_net = pql.sqldf(query_res_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fc81afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linear = pql.sqldf(query_res_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab473be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9e46dfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['who_win'] = df_net['who_win'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a1bdc55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('test_net.csv' ,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "689b6f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['who_win'] = df_linear['who_win'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "017756f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('test_Linear.csv' ,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0b568a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78971b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f616f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3c3124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e43784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904ec42c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd95668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4346ca61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
